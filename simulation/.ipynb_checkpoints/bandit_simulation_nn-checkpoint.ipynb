{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26837948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate_module import *\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7bf728",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_setting = {\"high_bw\": [10, .2],\n",
    "                \"medium_bw\": [1, .2],\n",
    "                \"low_bw\": [.5, .2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a703fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"n_tasks\": 15,\n",
    "    \"conservative\": True,\n",
    "    \"target_test_size\": 0.8,\n",
    "    \"model_type\": \"nn\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec34f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miaoxinran/Documents/projects/source_selection22_after_rej/source_selection/simulation/simulate_module.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  processed = (raw - raw.min(axis = 0)) / (raw.max(axis = 0) - raw.min(axis = 0))\n",
      "/Users/miaoxinran/Documents/projects/source_selection22_after_rej/source_selection/simulation/simulate_module.py:441: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(x).float()\n",
      "/Users/miaoxinran/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([20, 1, 1])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/miaoxinran/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([40, 1, 1])) that is different to the input size (torch.Size([40, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/miaoxinran/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([48, 1, 1])) that is different to the input size (torch.Size([48, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/miaoxinran/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([140, 1, 1])) that is different to the input size (torch.Size([140, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/miaoxinran/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1400, 1])) that is different to the input size (torch.Size([1400])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/miaoxinran/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([120, 1, 1])) that is different to the input size (torch.Size([120, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "for s in sigma_setting.keys():\n",
    "    # set directory\n",
    "    \n",
    "    if args[\"conservative\"]:\n",
    "        data_path = Path(args[\"model_type\"] + \"/conservative_derived_data\") \n",
    "    else:\n",
    "        data_path = Path(args[\"model_type\"] + \"/derived_data\")\n",
    "\n",
    "\n",
    "    data_path = Path(data_path)\n",
    "    working_path = data_path / s \n",
    "    working_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "    # generate data ------------------------------------------------\n",
    "    np.random.seed(1234)\n",
    "    f, betas, zs = random_functions(args[\"n_tasks\"], 6,\n",
    "                                    sigma_between = sigma_setting[s][0],\n",
    "                                    sigma_within = sigma_setting[s][-1])\n",
    "    result = []\n",
    "\n",
    "    for i, fi in enumerate(f):\n",
    "        x = np.random.uniform(0, 1, 100)\n",
    "        result.append({\n",
    "            \"task\": i,\n",
    "            \"x\": x,\n",
    "            \"f\": fi(x),\n",
    "            \"y\": fi(x) + np.random.normal(0, .1, len(x))\n",
    "        })\n",
    "\n",
    "    # save data\n",
    "    data_df = pd.concat([pd.DataFrame(r) for r in result])\n",
    "    data_df.to_csv(working_path / \"tasks.csv\", index = False)\n",
    "    data_df = data_df.reset_index()\n",
    "\n",
    "\n",
    "    betas_df = np.hstack([np.arange(args[\"n_tasks\"])[:, np.newaxis], np.array(zs)[:, np.newaxis], betas])\n",
    "    betas_df = pd.DataFrame(betas_df)\n",
    "    betas_df.columns = [\"task\", \"cluster\"] + [f\"beta{i}\" for i in range(betas.shape[1])]\n",
    "    betas_df.to_csv(working_path / \"betas.csv\", index = False)\n",
    "\n",
    "    # relationship between tasks (bandits) and their original clusters\n",
    "    #d = dict.fromkeys(betas_df.cluster, [])\n",
    "    #for k, v in zip(betas_df.cluster, betas_df.task):\n",
    "    #    d[k] = d[k] +[v]\n",
    "\n",
    "    data_dict = data_df.to_dict(orient = \"list\")\n",
    "\n",
    "    # add key \"cluster\" to `data_dict`\n",
    "    #data_dict[\"cluster\"] = []\n",
    "    #for task in data_dict[\"task\"]:\n",
    "        #cluster = get_key(d, task)\n",
    "        #if(cluster == \"There is no such key\"):\n",
    "            #print(\"task = \" + str(task))\n",
    "            #break\n",
    "        #data_dict[\"cluster\"].append(cluster)\n",
    "\n",
    "\n",
    "    # bandit selection ------------------------------------------------\n",
    "    for target_task in range(args[\"n_tasks\"]):\n",
    "        # prepare input\n",
    "        input_data = prepare_input(data_dict, target_task = target_task, target_test_size = args[\"target_test_size\"], \n",
    "                                  preprocess = True)\n",
    "        pd.DataFrame.from_dict(input_data[\"data_dict\"]).to_csv(working_path / \"tasks_processed.csv\", index = False)\n",
    "        # bandit selection\n",
    "        losses, alpha, beta, bandit_selects, pi, bl = bandit_source_train(input_data = input_data,\n",
    "                    model = nn(), batch_size = 8, decay_rate = .5, n_it = 100, loss_fn =  torch.nn.MSELoss(),\n",
    "                    conservative = args[\"conservative\"])\n",
    "        \n",
    "        # save outputs\n",
    "        output_dir = working_path / f\"target_{target_task}_{args['target_test_size']}\"\n",
    "        save_files(output_dir, alpha, beta, losses, bandit_selects, pi, bl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
