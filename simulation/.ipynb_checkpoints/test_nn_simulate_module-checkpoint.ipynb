{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19862d90",
   "metadata": {},
   "source": [
    "Testing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9af6c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate_module import *\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import torch\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4d27a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_setting = {\"high_bw\": [10, .2],\n",
    "                \"medium_bw\": [1, .2],\n",
    "                \"low_bw\": [.5, .2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0fb08e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"n_tasks\": 15,\n",
    "    \"conservative\": True,\n",
    "    \"target_test_size\": 0.8,\n",
    "    \"model_type\": \"nn\",\n",
    "    \"base_output_dir\": \"test\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "ae26cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"model_type\"] == \"lm\":\n",
    "    model_class = lm()\n",
    "    loss_fn = mse\n",
    "elif args[\"model_type\"] == \"nn\":\n",
    "    model_class = nn()\n",
    "    loss_fn =  torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "65f30a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"high_bw\"\n",
    "    # set directory\n",
    "if args[\"conservative\"]:\n",
    "    data_path = Path(args[\"base_output_dir\"]) / Path(\"model_\" + args[\"model_type\"] + \"/conservative_derived_data\")\n",
    "else:\n",
    "    data_path = Path(args[\"base_output_dir\"]) / Path(\"model_\" + args[\"model_type\"] + \"/derived_data\")\n",
    "data_path = Path(data_path)\n",
    "working_path = data_path / s\n",
    "working_path.mkdir(parents = True, exist_ok = True)\n",
    "# generate data ------------------------------------------------\n",
    "np.random.seed(1234)\n",
    "f, betas, zs = random_functions(args[\"n_tasks\"], 6,\n",
    "                                sigma_between = sigma_setting[s][0],\n",
    "                                sigma_within = sigma_setting[s][-1])\n",
    "result = []\n",
    "for i, fi in enumerate(f):\n",
    "    x = np.random.uniform(0, 1, 100)\n",
    "    result.append({\n",
    "        \"task\": i,\n",
    "        \"x\": x,\n",
    "        \"f\": fi(x)\n",
    "        \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "6918cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k , _ in enumerate(result):\n",
    "    \n",
    "    result[k][\"p\"] = 1 / (1 + np.exp(- result[k][\"x\"])) + np.random.normal(0, .1, len(result[k][\"x\"]))\n",
    "    result[k][\"y\"] = np.zeros((len(result[k][\"x\"]), 2))\n",
    "    for i, v in enumerate(result[k][\"p\"]):\n",
    "        if v > np.mean(result[k][\"p\"]):\n",
    "            result[k][\"y\"][i, 1] = 1\n",
    "        else:\n",
    "            result[k][\"y\"][i, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "65cd0b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k , _ in enumerate(result):\n",
    "    \n",
    "    result[k][\"p\"] = 1 / (1 + np.exp(- result[k][\"x\"])) + np.random.normal(0, .1, len(result[k][\"x\"]))\n",
    "    result[k][\"y\"] = np.zeros(len(result[k][\"x\"]))\n",
    "    for i, v in enumerate(result[k][\"p\"]):\n",
    "        if v > np.median(result[k][\"p\"]):\n",
    "            result[k][\"y\"][i] = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "44d1df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat([pd.DataFrame(r) for r in result])\n",
    "data_df.to_csv(working_path / \"tasks.csv\", index = False)\n",
    "data_df = data_df.reset_index()\n",
    "betas_df = np.hstack([np.arange(args[\"n_tasks\"])[:, np.newaxis], np.array(zs)[:, np.newaxis], betas])\n",
    "betas_df = pd.DataFrame(betas_df)\n",
    "betas_df.columns = [\"task\", \"cluster\"] + [f\"beta{i}\" for i in range(betas.shape[1])]\n",
    "betas_df.to_csv(working_path / \"betas.csv\", index = False)\n",
    "data_dict = data_df.to_dict(orient = \"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "91363a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn():\n",
    "    \"\"\"\n",
    "    Neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs = 1, n_outputs = 2, H = 200):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_inputs, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, n_outputs),\n",
    "        )\n",
    "    def initialize(self, n_inputs = 1, n_outputs = 2, H = 200):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_inputs, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, n_outputs),\n",
    "        )\n",
    "        return self\n",
    "    def prepare_data(self, x, y):\n",
    "        if type(x) != torch.Tensor:\n",
    "            if len(x.shape) > 1:\n",
    "                x = torch.tensor(x[:, 1:]).float()\n",
    "            else:\n",
    "                x = torch.tensor(x).float()\n",
    "        if type(y) != torch.Tensor:\n",
    "            y = torch.tensor(y).float()\n",
    "        return x, y\n",
    "    def fit(self, x_train, y_train, loss_fn = torch.nn.MSELoss(), n_epochs = 10, lr = 1e-4):\n",
    "        model = self.model\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr = lr)\n",
    "        for epoch in range(n_epochs):\n",
    "            # get loss\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = self.model(x_train[:, np.newaxis])\n",
    "            loss = loss_fn(y_train, y_hat)\n",
    "\n",
    "            # update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return self\n",
    "            \n",
    "        return model\n",
    "    def evaluate(self, x_test, y_test, loss_fn = torch.nn.MSELoss()):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self.model(x_test[:, np.newaxis])\n",
    "            l = loss_fn(y_test, y_hat)\n",
    "        return l\n",
    "    def pred(self, x_new):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self.model(x_new)\n",
    "        return y_hat\n",
    "    def combine_with_old(self, model_old, decay_rate = .5):\n",
    "        for i in range(len(model_old)):\n",
    "            if \"weight\" in dir(model_old[i]):\n",
    "                self.model[i].weight = torch.nn.Parameter(decay_rate * model_old[i].weight + (1 - decay_rate) * self.model[i].weight)\n",
    "                self.model[i].bias = torch.nn.Parameter(decay_rate * model_old[i].bias + (1 - decay_rate) * self.model[i].bias)\n",
    "    def save(self, path = \".\", x_new = None, y_new = None, para = True):\n",
    "        x_new, y_new = self.prepare_data(x_new, y_new)\n",
    "        path = Path(path)\n",
    "        path.mkdir(parents = True, exist_ok = True)\n",
    "        y_hat = self.pred(x_new)\n",
    "        if not x_new is None:\n",
    "            pd.DataFrame.from_dict({\"x\": [item[0] for item in x_new.tolist()], \n",
    "                        \"y\": y_new,\n",
    "                        \"y_hat\": [item[0] for item in y_hat.tolist()]\n",
    "                       }).to_csv(path / Path(\"fitted.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "9d9ed5b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'nn' has no attribute 'CrossEntropyLoss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-1b9ffe839837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'nn' has no attribute 'CrossEntropyLoss'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "16f5d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn():\n",
    "    \"\"\"\n",
    "    Neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs = 1, n_outputs = 2, H = 200):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_inputs, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, n_outputs),\n",
    "        )\n",
    "    def initialize(self, n_inputs = 1, n_outputs = 2, H = 200):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_inputs, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, n_outputs),\n",
    "        )\n",
    "        return self\n",
    "    def prepare_data(self, x, y, binary = True):\n",
    "        if type(x) != torch.Tensor:\n",
    "            if len(x.shape) > 1:\n",
    "                x = torch.tensor(x[:, 1:]).float()\n",
    "            else:\n",
    "                x = torch.tensor(x).float()\n",
    "        if (binary is True) and (len(y.shape) == 1):\n",
    "            y = np.array([y, 1-y]).T\n",
    "        if type(y) != torch.Tensor:\n",
    "            y = torch.tensor(y).float()\n",
    "        return x, y\n",
    "    def fit(self, x_train, y_train, loss_fn = torch.nn.MSELoss(), n_epochs = 10, lr = 1e-4):\n",
    "        model = self.model\n",
    "        #optimizer = torch.optim.Adam(self.model.parameters(), lr = lr)\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr = lr, momentum=0.9)\n",
    "        for epoch in range(n_epochs):\n",
    "            # get loss\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = self.model(x_train[:, np.newaxis])\n",
    "            loss = loss_fn(y_train, y_hat)\n",
    "\n",
    "            # update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return self\n",
    "            \n",
    "        return model\n",
    "    def evaluate(self, x_test, y_test, loss_fn = torch.nn.MSELoss()):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self.model(x_test[:, np.newaxis])\n",
    "            l = loss_fn(y_test, y_hat)\n",
    "        return l\n",
    "    def pred(self, x_new):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self.model(x_new)\n",
    "        return y_hat\n",
    "    def combine_with_old(self, model_old, decay_rate = .5):\n",
    "        for i in range(len(model_old)):\n",
    "            if \"weight\" in dir(model_old[i]):\n",
    "                self.model[i].weight = torch.nn.Parameter(decay_rate * model_old[i].weight + (1 - decay_rate) * self.model[i].weight)\n",
    "                self.model[i].bias = torch.nn.Parameter(decay_rate * model_old[i].bias + (1 - decay_rate) * self.model[i].bias)\n",
    "    def save(self, path = \".\", x_new = None, y_new = None, para = True, binary = True):\n",
    "        x_new, y_new = self.prepare_data(x_new, y_new)\n",
    "        path = Path(path)\n",
    "        path.mkdir(parents = True, exist_ok = True)\n",
    "        y_hat = self.pred(x_new)\n",
    "        if not x_new is None:\n",
    "            pd.DataFrame.from_dict({\"x\": [item[0] for item in x_new.tolist()], \n",
    "                        \"y\": y_new,\n",
    "                        \"y_hat\": [item[0] for item in y_hat.tolist()]\n",
    "                       }).to_csv(path / Path(\"fitted.csv\"))\n",
    "        if binary is True:\n",
    "            \n",
    "            pd.DataFrame.from_dict({\"x\": [item[0] for item in x_new.tolist()], \n",
    "                        \"y\": torch.max(y_new, 1).indices.tolist(),\n",
    "                        \"y_hat\": torch.max(y_hat, 1).indices.tolist()\n",
    "                       }).to_csv(path / Path(\"fitted.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d004bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def subset_data(data_dict, key_name = \"task\", key_value = 0, test_size = 0.33):\n",
    "    \"\"\"\n",
    "    Subsetting data by the value of a key.\n",
    "    \n",
    "    Parameters\n",
    "    ---\n",
    "    data_dict: dict\n",
    "        the dictionary one wants to subset\n",
    "    key_name: str\n",
    "        the key one wants to subset on\n",
    "    key_value: list / int / str\n",
    "        the value of the key desirable in the output subset\n",
    "    test_size: float\n",
    "        how to split the resulting subset; if set to zero, then the output won't be splitted\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "    \n",
    "    \"\"\"\n",
    "    if type(data_dict[key_name]) == list:\n",
    "        values = data_dict[key_name]\n",
    "    else:\n",
    "        values = list(data_dict[key_name].values())\n",
    "    \n",
    "    n_task = max(values) + 1    \n",
    "    if type(key_value) != list:\n",
    "        idx_task = [i for (i, v) in enumerate(values) if v == key_value]\n",
    "    else:\n",
    "        idx_task = [i for (i, v) in enumerate(values) if v in key_value]\n",
    "        \n",
    "    tasks = [data_dict['task'][i] for i in idx_task]\n",
    "    \n",
    "    \n",
    "    x = [data_dict['x'][i] for i in idx_task]\n",
    "    y = np.array([data_dict['y'][i] for i in idx_task])\n",
    "    X = np.array([np.ones(len(idx_task)), np.array(x)]).T\n",
    "    \n",
    "    if test_size == 0:\n",
    "        return X, y, tasks\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size = test_size,\n",
    "                                                        random_state = 123,\n",
    "                                                           stratify = y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2d7f425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(data_dict, target_task, target_test_size, preprocess = True):\n",
    "    \"\"\"\n",
    "    Preparing input data for bandit selection\n",
    "    \n",
    "    Parameters\n",
    "    ---\n",
    "    data_dict: dict\n",
    "        all data, including source and target\n",
    "    target_task: int\n",
    "        data with data_dict[\"task\"] equals to target_task will be in the target\n",
    "    target_test_size: float\n",
    "        within [0, 1) indicating the proportion of the validation + test set.\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    input_data: dict\n",
    "        keys including data_dict, source_dict,\n",
    "                        source_task, source_cluster,\n",
    "                        X_target_train, X_target_test, X_target_val, y_target_train, y_target_test, y_target_val\n",
    "    \"\"\"\n",
    "    \n",
    "    n_tasks = max(data_dict[\"task\"]) + 1\n",
    "\n",
    "\n",
    "    input_data = {\"data_dict\": data_dict}\n",
    "    input_data[\"X_target_train\"], input_data[\"X_target_test\"], input_data[\"y_target_train\"], input_data[\"y_target_test\"] = subset_data(data_dict, key_value = target_task, key_name = \"task\",\n",
    "                                                                                                                                      test_size = target_test_size)\n",
    "    input_data[\"X_target_val\"], input_data[\"X_target_test\"], input_data[\"y_target_val\"], input_data[\"y_target_test\"] = train_test_split(input_data[\"X_target_test\"], input_data[\"y_target_test\"], \n",
    "                                                        test_size = .5,\n",
    "                                                        random_state = 123, stratify = input_data[\"y_target_test\"]  )\n",
    "        \n",
    "    input_data[\"source_task\"] = [v for v in range(n_tasks) if v != target_task]\n",
    "    \n",
    "    \n",
    "    idx_source = [i for (i, v) in enumerate(data_dict['task']) if v != target_task]\n",
    "    \n",
    "    # source data\n",
    "    input_data[\"source_dict\"] = {}\n",
    "    for key_name in data_dict.keys():\n",
    "        input_data[\"source_dict\"][key_name] = [data_dict[key_name][i] for i in idx_source]\n",
    "    \n",
    "    \n",
    "    if preprocess:\n",
    "        input_data[\"data_dict\"] = pre(raw_data = input_data[\"data_dict\"]).pre_process(key_names = [\"y\", \"x\", \"f\"], by_key = \"task\")\n",
    "        input_data[\"source_dict\"] = pre(raw_data = input_data[\"source_dict\"]).pre_process(key_names = [\"y\", \"x\"], by_key = \"task\")\n",
    "        input_data = pre(raw_data = input_data).pre_process(key_names = [\"X_target_test\", \"X_target_val\", \"X_target_train\",\n",
    "                                          \"y_target_train\", \"y_target_val\", \"y_target_test\"], by_key = None)\n",
    "    \n",
    "    return(input_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9063506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miaoxinran/Documents/projects/source_selection22/source_selection/simulation/simulate_module.py:84: RuntimeWarning: invalid value encountered in true_divide\n",
      "  processed = (raw - raw.min(axis = 0)) / (raw.max(axis = 0) - raw.min(axis = 0))\n"
     ]
    }
   ],
   "source": [
    "input_data = prepare_input(data_dict,\n",
    "                               target_task = 4,\n",
    "                               target_test_size = 0.6,\n",
    "                              preprocess = True)\n",
    "pd.DataFrame.from_dict(input_data[\"data_dict\"]).to_csv(working_path / \"tasks_processed.csv\",\n",
    "                                                           index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "456a0c5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-258-cfe0462d27c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1048\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2383\u001b[0m         )\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.model.parameters(), lr = 1e-4, momentum=0.9)\n",
    "for epoch in range(10):\n",
    "    # get loss\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model.model(val_x[:, np.newaxis])\n",
    "    loss = loss_fn(val_y, y_hat)\n",
    "\n",
    "    # update weights\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "964b4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 2, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(2)\n",
    "output = loss_fn(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "b917a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.pred(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "1e4dc6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(y_hat,1).indices.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "28aef55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "897c6819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BCELoss()(val_y, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(y_hat,1).indices.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "6411494b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BCELoss()(val_y[:,0], val_y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "98006680",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([30])) that is different to the input size (torch.Size([30, 2])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-320-0204de5fc178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2750\u001b[0m         raise ValueError(\n\u001b[1;32m   2751\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2752\u001b[0;31m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2753\u001b[0m         )\n\u001b[1;32m   2754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([30])) that is different to the input size (torch.Size([30, 2])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "torch.nn.BCELoss()(y_hat, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "14df9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "?loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e51fc6b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-ba51ea7e4d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m mod.fit(torch.Tensor(result[0][\"x\"]),\n\u001b[1;32m      3\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         n_epochs = 100, loss_fn = loss_fn)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-231-77833b7e32c5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, loss_fn, n_epochs, lr)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1048\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log_softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "mod = nn()\n",
    "mod.fit(torch.Tensor(result[0][\"x\"]),\n",
    "        torch.Tensor(result[0][\"f\"]),\n",
    "        n_epochs = 100, loss_fn = loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "93a0a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = mod.pred(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a224fe3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.1467, 0.1502, 0.1532, 0.1446, 0.1478, 0.1538, 0.1553, 0.1557, 0.1408,\n",
       "        0.1466, 0.1532, 0.1443, 0.1556, 0.1434, 0.1387, 0.1561, 0.1416, 0.1443,\n",
       "        0.1558, 0.1361, 0.1549, 0.1410, 0.1390, 0.1482, 0.1539, 0.1420, 0.1549,\n",
       "        0.1563, 0.1511, 0.1371]),\n",
       "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "bb2381ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn(n_inputs = 1)\n",
    "n_it = 100\n",
    "batch_size = 64\n",
    "decay_rate = .5\n",
    "conservative = False\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "51ec47bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-28d6be2642aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# initialize model from target training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X_target_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y_target_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-231-77833b7e32c5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, loss_fn, n_epochs, lr)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1048\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2383\u001b[0m         )\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "bandit_selects = [None]\n",
    "# initialize hyperparameters\n",
    "alpha = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "beta = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "pi = dict.fromkeys(input_data[\"source_task\"], [0])\n",
    "\n",
    "mod = nn()\n",
    "val_x, val_y = mod.prepare_data(input_data[\"X_target_val\"], input_data[\"y_target_val\"])\n",
    "\n",
    "# initialize model from target training data\n",
    "X_current, y_current = mod.prepare_data(input_data[\"X_target_train\"], input_data[\"y_target_train\"])\n",
    "mod.fit( X_current, y_current, n_epochs = 100, loss_fn = loss_fn)\n",
    "l = mod.evaluate(val_x, val_y, loss_fn = loss_fn)\n",
    "losses = [l]\n",
    "model_old = copy.deepcopy(mod.model)\n",
    "\n",
    "for t in range(n_it):\n",
    "    # select bandit\n",
    "    bandit_current, pi = get_bandit(input_data, alpha, beta,t, pi)\n",
    "    bandit_selects.append(bandit_current)\n",
    "    \n",
    "    # set training data at this iteration\n",
    "    X_current, y_current, _ = subset_data(input_data[\"source_dict\"], \n",
    "                               key_value = bandit_current,\n",
    "                               key_name = \"task\", test_size = 0)\n",
    "    batch_id = random.choices(list(range(0, len(y_current))), k = batch_size)\n",
    "    X_current, y_current = X_current[batch_id, :], y_current[batch_id]\n",
    "\n",
    "    #X_current = np.concatenate((X_current, input_data[\"X_target_val\"]), axis = 0)\n",
    "    #y_current = np.concatenate((y_current, input_data[\"y_target_val\"]), axis = 0)\n",
    "    \n",
    "    X_current, y_current = mod.prepare_data(X_current, y_current)\n",
    "    # train model\n",
    "    #mod = model.initialize(n_inputs = 1)\n",
    "    mod = nn()\n",
    "    mod.fit(X_current, y_current, loss_fn = loss_fn, n_epochs = 200)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # combine parameters with previous model\n",
    "    #mod.combine_with_old(model_old, decay_rate = 1)\n",
    "    \n",
    "    # evaluate model\n",
    "    l = mod.evaluate(val_x, val_y, loss_fn = loss_fn)\n",
    "    losses += [l]\n",
    "    model_old = copy.deepcopy(mod.model)\n",
    "    print(t, \", current = \", mod.model[2].weight[0,0].detach().numpy(),\n",
    "          \", old = \", model_old[2].weight[0,0].detach().numpy())\n",
    "    # update bandit parameters\n",
    "    if conservative:\n",
    "        thres = 100000\n",
    "    else:\n",
    "        thres = avg_loss(bandit_selects, losses, bandit_current)\n",
    "    alpha, beta = update_hyper_para(alpha, beta, t, losses,\n",
    "                                    bandit_current,\n",
    "                                    thres = thres\n",
    "                                   )\n",
    "    mod.save(path = working_path / (\"current\" + str(t)), x_new = X_current, y_new = y_current, para = True)\n",
    "    mod.save(path = working_path / str(t), x_new = val_x, y_new = val_y, para = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "757b40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_files(working_path, alpha, beta, losses, bandit_selects, pi, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "a3b14c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.nn at 0x7ff3310f7390>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "519a7331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"weight\" in dir(model_old[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "678288ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-24cb35de8d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\", old = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm2' is not defined"
     ]
    }
   ],
   "source": [
    "m1 = nn()\n",
    "m1.initialize()\n",
    "print(m1.model[2].weight[0,0].detach().numpy(), \", old = \", m2[2].weight[0,0].detach().numpy())\n",
    "\n",
    "\n",
    "m1.fit(val_x, val_y)\n",
    "\n",
    "m2 = copy.deepcopy(m1.model)\n",
    "print(m1.model[2].weight[0,0].detach().numpy(), \", old = \", m2[2].weight[0,0].detach().numpy())\n",
    "\n",
    "\n",
    "m1.fit(X_current, y_current)\n",
    "\n",
    "print(m1.model[2].weight[0,0].detach().numpy(), \", old = \", m2[2].weight[0,0].detach().numpy())\n",
    "\n",
    "m1.combine_with_old(m2)\n",
    "print(m1.model[2].weight[0,0].detach().numpy(), \", old = \", m2[2].weight[0,0].detach().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "48b6fa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0016189963 , old =  -0.0016189963\n",
      "-0.0025594335 , old =  -0.0016189963\n"
     ]
    }
   ],
   "source": [
    "m1 = nn()\n",
    "#m1.initialize()\n",
    "m2 = copy.deepcopy(m1.model)\n",
    "print(m1.model[2].weight[0,0].detach().numpy(), \", old = \", m2[2].weight[0,0].detach().numpy())\n",
    "\n",
    "m1.fit(X_current, y_current)\n",
    "print(m1.model[2].weight[0,0].detach().numpy(), \", old = \", m2[2].weight[0,0].detach().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "75d8e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn()\n",
    "for i in range(len(model_old)):\n",
    "    if \"weight\" in dir(model_old[i]):\n",
    "        m.model[i].weight = torch.nn.Parameter(decay_rate * m2[i].weight + (1 - decay_rate) * m1.model[i].weight)\n",
    "        m.model[i].bias = torch.nn.Parameter(decay_rate * m2[i].bias + (1 - decay_rate) * m1.model[i].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "d6f7876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0025594335 , old =  -0.0016189963 , combined =  -0.002089215\n"
     ]
    }
   ],
   "source": [
    "print(m1.model[2].weight[0,0].detach().numpy(), \", old = \", m2[2].weight[0,0].detach().numpy(),\n",
    "     \", combined = \", m.model[2].weight[0,0].detach().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "96723613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.002089215\n"
     ]
    }
   ],
   "source": [
    "print( m.model[2].weight[0,0].detach().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "a79305d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    m.model[i].weight = torch.nn.Parameter((1 - decay_rate) * m1.model[i].weight)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "c748b499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.6045e-01],\n",
       "        [-9.5524e-01],\n",
       "        [-3.4400e-01],\n",
       "        [-4.8876e-01],\n",
       "        [ 3.3856e-01],\n",
       "        [-4.2939e-01],\n",
       "        [-1.8414e-01],\n",
       "        [ 6.7081e-01],\n",
       "        [-2.4606e-01],\n",
       "        [ 5.0031e-01],\n",
       "        [ 3.9142e-01],\n",
       "        [ 9.4209e-01],\n",
       "        [-8.4760e-01],\n",
       "        [ 2.8412e-01],\n",
       "        [ 5.4026e-01],\n",
       "        [ 1.3439e-01],\n",
       "        [-9.6698e-01],\n",
       "        [-2.2254e-01],\n",
       "        [ 8.0466e-01],\n",
       "        [ 4.7003e-01],\n",
       "        [-8.2490e-01],\n",
       "        [-7.9714e-01],\n",
       "        [-7.9142e-01],\n",
       "        [-6.8677e-01],\n",
       "        [ 1.2869e-01],\n",
       "        [ 1.8085e-02],\n",
       "        [ 4.3363e-01],\n",
       "        [-3.7638e-01],\n",
       "        [-3.4960e-01],\n",
       "        [-6.9998e-01],\n",
       "        [-5.2267e-01],\n",
       "        [ 4.2390e-01],\n",
       "        [-3.5713e-01],\n",
       "        [-3.7963e-01],\n",
       "        [-6.5039e-01],\n",
       "        [-1.5799e-01],\n",
       "        [ 8.0255e-01],\n",
       "        [-2.2448e-01],\n",
       "        [ 3.4777e-01],\n",
       "        [ 7.5226e-01],\n",
       "        [ 5.8573e-01],\n",
       "        [-3.2338e-01],\n",
       "        [ 3.4219e-01],\n",
       "        [-7.2575e-02],\n",
       "        [ 1.0517e-01],\n",
       "        [-5.6193e-01],\n",
       "        [ 4.8598e-01],\n",
       "        [ 7.2578e-01],\n",
       "        [-1.0778e-01],\n",
       "        [ 7.9384e-01],\n",
       "        [ 5.0060e-01],\n",
       "        [-9.8211e-02],\n",
       "        [-7.4437e-01],\n",
       "        [-1.5281e-02],\n",
       "        [-7.6608e-01],\n",
       "        [-3.5246e-01],\n",
       "        [ 6.0075e-01],\n",
       "        [ 1.1003e-01],\n",
       "        [ 4.5117e-01],\n",
       "        [ 3.5215e-01],\n",
       "        [-1.9446e-01],\n",
       "        [-3.2571e-01],\n",
       "        [-1.3083e-01],\n",
       "        [-4.8180e-01],\n",
       "        [-7.3029e-01],\n",
       "        [ 3.4442e-01],\n",
       "        [ 7.4188e-01],\n",
       "        [ 4.8791e-02],\n",
       "        [-1.8143e-01],\n",
       "        [ 5.2581e-01],\n",
       "        [ 9.9826e-01],\n",
       "        [ 6.5577e-01],\n",
       "        [-4.1994e-01],\n",
       "        [ 1.4310e-01],\n",
       "        [-7.2650e-02],\n",
       "        [-4.7927e-01],\n",
       "        [-3.1780e-01],\n",
       "        [-2.4409e-01],\n",
       "        [ 6.1162e-01],\n",
       "        [ 1.0902e-01],\n",
       "        [ 8.3321e-03],\n",
       "        [ 9.6121e-01],\n",
       "        [ 6.3865e-01],\n",
       "        [-8.1649e-01],\n",
       "        [ 3.6477e-01],\n",
       "        [-8.9391e-01],\n",
       "        [-1.4037e-01],\n",
       "        [-1.6938e-01],\n",
       "        [-9.3978e-01],\n",
       "        [-1.0534e-01],\n",
       "        [ 9.0191e-01],\n",
       "        [ 1.0797e-01],\n",
       "        [-4.5858e-01],\n",
       "        [ 3.9365e-01],\n",
       "        [-4.3191e-01],\n",
       "        [-4.7138e-01],\n",
       "        [-2.2707e-01],\n",
       "        [ 4.3691e-01],\n",
       "        [ 6.4505e-01],\n",
       "        [-6.9895e-01],\n",
       "        [ 5.6876e-01],\n",
       "        [ 5.2267e-01],\n",
       "        [-6.8013e-01],\n",
       "        [ 4.9438e-01],\n",
       "        [ 5.2174e-01],\n",
       "        [ 5.8567e-02],\n",
       "        [-4.7230e-01],\n",
       "        [ 7.6835e-01],\n",
       "        [ 5.4466e-01],\n",
       "        [ 9.3459e-01],\n",
       "        [ 9.9988e-01],\n",
       "        [-6.0489e-01],\n",
       "        [-9.1422e-04],\n",
       "        [-7.7769e-01],\n",
       "        [ 7.1428e-01],\n",
       "        [ 2.3983e-01],\n",
       "        [-4.2061e-01],\n",
       "        [-1.7521e-01],\n",
       "        [-8.2881e-01],\n",
       "        [-8.1009e-01],\n",
       "        [ 1.7338e-01],\n",
       "        [-6.8162e-01],\n",
       "        [ 1.0421e-01],\n",
       "        [-5.5166e-01],\n",
       "        [-2.0638e-01],\n",
       "        [ 8.3615e-01],\n",
       "        [-7.5951e-02],\n",
       "        [ 6.6441e-01],\n",
       "        [-9.5059e-01],\n",
       "        [ 6.8918e-01],\n",
       "        [-4.1803e-02],\n",
       "        [ 8.2755e-01],\n",
       "        [-9.7584e-01],\n",
       "        [ 4.5631e-01],\n",
       "        [ 6.9581e-01],\n",
       "        [-4.4177e-01],\n",
       "        [ 6.4733e-01],\n",
       "        [ 5.6934e-01],\n",
       "        [ 5.1005e-02],\n",
       "        [-4.8574e-01],\n",
       "        [-8.7569e-02],\n",
       "        [ 3.6354e-01],\n",
       "        [-1.6386e-01],\n",
       "        [ 7.4103e-01],\n",
       "        [-8.5627e-01],\n",
       "        [ 9.3451e-01],\n",
       "        [ 5.3252e-01],\n",
       "        [-2.6219e-01],\n",
       "        [-9.6810e-01],\n",
       "        [ 9.1786e-02],\n",
       "        [-8.0581e-01],\n",
       "        [-8.1674e-01],\n",
       "        [-1.6677e-01],\n",
       "        [-4.9397e-01],\n",
       "        [ 5.6320e-01],\n",
       "        [-9.9802e-01],\n",
       "        [ 8.2105e-01],\n",
       "        [ 8.3483e-01],\n",
       "        [ 6.2827e-01],\n",
       "        [-8.4676e-01],\n",
       "        [-9.5304e-01],\n",
       "        [-6.6560e-01],\n",
       "        [-5.6177e-01],\n",
       "        [-4.2780e-01],\n",
       "        [ 7.5067e-01],\n",
       "        [-5.1110e-01],\n",
       "        [ 4.0150e-01],\n",
       "        [-6.5554e-01],\n",
       "        [-9.3261e-01],\n",
       "        [-2.4611e-01],\n",
       "        [-6.9530e-01],\n",
       "        [-7.2104e-01],\n",
       "        [-5.9816e-01],\n",
       "        [-1.6914e-02],\n",
       "        [-5.0776e-01],\n",
       "        [ 3.2401e-01],\n",
       "        [ 4.9507e-01],\n",
       "        [ 6.1214e-01],\n",
       "        [ 6.7357e-01],\n",
       "        [ 1.9539e-01],\n",
       "        [-8.6088e-01],\n",
       "        [ 3.7174e-01],\n",
       "        [-7.8583e-01],\n",
       "        [ 1.1592e-01],\n",
       "        [-1.9714e-01],\n",
       "        [ 3.8759e-01],\n",
       "        [-7.7372e-01],\n",
       "        [-7.6976e-01],\n",
       "        [ 4.2678e-01],\n",
       "        [ 7.4022e-01],\n",
       "        [ 6.8270e-01],\n",
       "        [ 9.1979e-01],\n",
       "        [ 7.4579e-01],\n",
       "        [-2.0905e-01],\n",
       "        [ 7.5617e-01],\n",
       "        [ 8.1763e-01],\n",
       "        [ 8.7338e-01],\n",
       "        [ 1.4589e-01],\n",
       "        [ 1.2969e-02],\n",
       "        [-7.1343e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2[0].weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "4ab45ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.5948e-01],\n",
       "        [-9.5524e-01],\n",
       "        [-3.4304e-01],\n",
       "        [-4.8876e-01],\n",
       "        [ 3.3856e-01],\n",
       "        [-4.2939e-01],\n",
       "        [-1.8414e-01],\n",
       "        [ 6.7081e-01],\n",
       "        [-2.4606e-01],\n",
       "        [ 5.0132e-01],\n",
       "        [ 3.9088e-01],\n",
       "        [ 9.4305e-01],\n",
       "        [-8.4760e-01],\n",
       "        [ 2.8347e-01],\n",
       "        [ 5.4125e-01],\n",
       "        [ 1.3438e-01],\n",
       "        [-9.6762e-01],\n",
       "        [-2.2254e-01],\n",
       "        [ 8.0567e-01],\n",
       "        [ 4.7050e-01],\n",
       "        [-8.2392e-01],\n",
       "        [-7.9714e-01],\n",
       "        [-7.9142e-01],\n",
       "        [-6.8773e-01],\n",
       "        [ 1.2947e-01],\n",
       "        [ 1.7246e-02],\n",
       "        [ 4.3447e-01],\n",
       "        [-3.7638e-01],\n",
       "        [-3.5059e-01],\n",
       "        [-6.9917e-01],\n",
       "        [-5.2172e-01],\n",
       "        [ 4.2303e-01],\n",
       "        [-3.5800e-01],\n",
       "        [-3.8059e-01],\n",
       "        [-6.5039e-01],\n",
       "        [-1.5890e-01],\n",
       "        [ 8.0190e-01],\n",
       "        [-2.2448e-01],\n",
       "        [ 3.4873e-01],\n",
       "        [ 7.5129e-01],\n",
       "        [ 5.8590e-01],\n",
       "        [-3.2338e-01],\n",
       "        [ 3.4219e-01],\n",
       "        [-7.2575e-02],\n",
       "        [ 1.0517e-01],\n",
       "        [-5.6193e-01],\n",
       "        [ 4.8598e-01],\n",
       "        [ 7.2670e-01],\n",
       "        [-1.0678e-01],\n",
       "        [ 7.9482e-01],\n",
       "        [ 5.0060e-01],\n",
       "        [-9.8211e-02],\n",
       "        [-7.4337e-01],\n",
       "        [-1.5281e-02],\n",
       "        [-7.6509e-01],\n",
       "        [-3.5246e-01],\n",
       "        [ 6.0041e-01],\n",
       "        [ 1.1003e-01],\n",
       "        [ 4.5021e-01],\n",
       "        [ 3.5116e-01],\n",
       "        [-1.9446e-01],\n",
       "        [-3.2571e-01],\n",
       "        [-1.3183e-01],\n",
       "        [-4.8180e-01],\n",
       "        [-7.3029e-01],\n",
       "        [ 3.4351e-01],\n",
       "        [ 7.4174e-01],\n",
       "        [ 4.7898e-02],\n",
       "        [-1.8059e-01],\n",
       "        [ 5.2486e-01],\n",
       "        [ 9.9927e-01],\n",
       "        [ 6.5671e-01],\n",
       "        [-4.2072e-01],\n",
       "        [ 1.4361e-01],\n",
       "        [-7.2650e-02],\n",
       "        [-4.7927e-01],\n",
       "        [-3.1829e-01],\n",
       "        [-2.4315e-01],\n",
       "        [ 6.1064e-01],\n",
       "        [ 1.0902e-01],\n",
       "        [ 9.2860e-03],\n",
       "        [ 9.6170e-01],\n",
       "        [ 6.3767e-01],\n",
       "        [-8.1649e-01],\n",
       "        [ 3.6578e-01],\n",
       "        [-8.9296e-01],\n",
       "        [-1.4037e-01],\n",
       "        [-1.7034e-01],\n",
       "        [-9.3979e-01],\n",
       "        [-1.0470e-01],\n",
       "        [ 9.0113e-01],\n",
       "        [ 1.0705e-01],\n",
       "        [-4.5959e-01],\n",
       "        [ 3.9433e-01],\n",
       "        [-4.3091e-01],\n",
       "        [-4.7047e-01],\n",
       "        [-2.2666e-01],\n",
       "        [ 4.3792e-01],\n",
       "        [ 6.4574e-01],\n",
       "        [-6.9895e-01],\n",
       "        [ 5.6782e-01],\n",
       "        [ 5.2360e-01],\n",
       "        [-6.8013e-01],\n",
       "        [ 4.9387e-01],\n",
       "        [ 5.2269e-01],\n",
       "        [ 5.8567e-02],\n",
       "        [-4.7199e-01],\n",
       "        [ 7.6835e-01],\n",
       "        [ 5.4561e-01],\n",
       "        [ 9.3476e-01],\n",
       "        [ 9.9988e-01],\n",
       "        [-6.0489e-01],\n",
       "        [-9.1422e-04],\n",
       "        [-7.7798e-01],\n",
       "        [ 7.1428e-01],\n",
       "        [ 2.3907e-01],\n",
       "        [-4.2061e-01],\n",
       "        [-1.7423e-01],\n",
       "        [-8.2781e-01],\n",
       "        [-8.0987e-01],\n",
       "        [ 1.7245e-01],\n",
       "        [-6.8064e-01],\n",
       "        [ 1.0519e-01],\n",
       "        [-5.5248e-01],\n",
       "        [-2.0658e-01],\n",
       "        [ 8.3711e-01],\n",
       "        [-7.6920e-02],\n",
       "        [ 6.6351e-01],\n",
       "        [-9.5159e-01],\n",
       "        [ 6.8918e-01],\n",
       "        [-4.1803e-02],\n",
       "        [ 8.2668e-01],\n",
       "        [-9.7484e-01],\n",
       "        [ 4.5570e-01],\n",
       "        [ 6.9581e-01],\n",
       "        [-4.4177e-01],\n",
       "        [ 6.4644e-01],\n",
       "        [ 5.6934e-01],\n",
       "        [ 5.1005e-02],\n",
       "        [-4.8574e-01],\n",
       "        [-8.6714e-02],\n",
       "        [ 3.6354e-01],\n",
       "        [-1.6386e-01],\n",
       "        [ 7.4202e-01],\n",
       "        [-8.5627e-01],\n",
       "        [ 9.3551e-01],\n",
       "        [ 5.3154e-01],\n",
       "        [-2.6319e-01],\n",
       "        [-9.6862e-01],\n",
       "        [ 9.2432e-02],\n",
       "        [-8.0581e-01],\n",
       "        [-8.1757e-01],\n",
       "        [-1.6777e-01],\n",
       "        [-4.9470e-01],\n",
       "        [ 5.6222e-01],\n",
       "        [-9.9802e-01],\n",
       "        [ 8.2195e-01],\n",
       "        [ 8.3401e-01],\n",
       "        [ 6.2754e-01],\n",
       "        [-8.4777e-01],\n",
       "        [-9.5205e-01],\n",
       "        [-6.6560e-01],\n",
       "        [-5.6177e-01],\n",
       "        [-4.2684e-01],\n",
       "        [ 7.5165e-01],\n",
       "        [-5.1110e-01],\n",
       "        [ 4.0137e-01],\n",
       "        [-6.5554e-01],\n",
       "        [-9.3355e-01],\n",
       "        [-2.4674e-01],\n",
       "        [-6.9530e-01],\n",
       "        [-7.2104e-01],\n",
       "        [-5.9871e-01],\n",
       "        [-1.5917e-02],\n",
       "        [-5.0678e-01],\n",
       "        [ 3.2413e-01],\n",
       "        [ 4.9438e-01],\n",
       "        [ 6.1214e-01],\n",
       "        [ 6.7261e-01],\n",
       "        [ 1.9539e-01],\n",
       "        [-8.6088e-01],\n",
       "        [ 3.7254e-01],\n",
       "        [-7.8583e-01],\n",
       "        [ 1.1692e-01],\n",
       "        [-1.9617e-01],\n",
       "        [ 3.8759e-01],\n",
       "        [-7.7449e-01],\n",
       "        [-7.7077e-01],\n",
       "        [ 4.2779e-01],\n",
       "        [ 7.4115e-01],\n",
       "        [ 6.8270e-01],\n",
       "        [ 9.1928e-01],\n",
       "        [ 7.4533e-01],\n",
       "        [-2.0996e-01],\n",
       "        [ 7.5617e-01],\n",
       "        [ 8.1663e-01],\n",
       "        [ 8.7439e-01],\n",
       "        [ 1.4503e-01],\n",
       "        [ 1.2969e-02],\n",
       "        [-7.1343e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.model[0].weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "3227653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.model[0].weight = m2[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "91f62539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.6045e-01],\n",
       "        [-9.5524e-01],\n",
       "        [-3.4400e-01],\n",
       "        [-4.8876e-01],\n",
       "        [ 3.3856e-01],\n",
       "        [-4.2939e-01],\n",
       "        [-1.8414e-01],\n",
       "        [ 6.7081e-01],\n",
       "        [-2.4606e-01],\n",
       "        [ 5.0031e-01],\n",
       "        [ 3.9142e-01],\n",
       "        [ 9.4209e-01],\n",
       "        [-8.4760e-01],\n",
       "        [ 2.8412e-01],\n",
       "        [ 5.4026e-01],\n",
       "        [ 1.3439e-01],\n",
       "        [-9.6698e-01],\n",
       "        [-2.2254e-01],\n",
       "        [ 8.0466e-01],\n",
       "        [ 4.7003e-01],\n",
       "        [-8.2490e-01],\n",
       "        [-7.9714e-01],\n",
       "        [-7.9142e-01],\n",
       "        [-6.8677e-01],\n",
       "        [ 1.2869e-01],\n",
       "        [ 1.8085e-02],\n",
       "        [ 4.3363e-01],\n",
       "        [-3.7638e-01],\n",
       "        [-3.4960e-01],\n",
       "        [-6.9998e-01],\n",
       "        [-5.2267e-01],\n",
       "        [ 4.2390e-01],\n",
       "        [-3.5713e-01],\n",
       "        [-3.7963e-01],\n",
       "        [-6.5039e-01],\n",
       "        [-1.5799e-01],\n",
       "        [ 8.0255e-01],\n",
       "        [-2.2448e-01],\n",
       "        [ 3.4777e-01],\n",
       "        [ 7.5226e-01],\n",
       "        [ 5.8573e-01],\n",
       "        [-3.2338e-01],\n",
       "        [ 3.4219e-01],\n",
       "        [-7.2575e-02],\n",
       "        [ 1.0517e-01],\n",
       "        [-5.6193e-01],\n",
       "        [ 4.8598e-01],\n",
       "        [ 7.2578e-01],\n",
       "        [-1.0778e-01],\n",
       "        [ 7.9384e-01],\n",
       "        [ 5.0060e-01],\n",
       "        [-9.8211e-02],\n",
       "        [-7.4437e-01],\n",
       "        [-1.5281e-02],\n",
       "        [-7.6608e-01],\n",
       "        [-3.5246e-01],\n",
       "        [ 6.0075e-01],\n",
       "        [ 1.1003e-01],\n",
       "        [ 4.5117e-01],\n",
       "        [ 3.5215e-01],\n",
       "        [-1.9446e-01],\n",
       "        [-3.2571e-01],\n",
       "        [-1.3083e-01],\n",
       "        [-4.8180e-01],\n",
       "        [-7.3029e-01],\n",
       "        [ 3.4442e-01],\n",
       "        [ 7.4188e-01],\n",
       "        [ 4.8791e-02],\n",
       "        [-1.8143e-01],\n",
       "        [ 5.2581e-01],\n",
       "        [ 9.9826e-01],\n",
       "        [ 6.5577e-01],\n",
       "        [-4.1994e-01],\n",
       "        [ 1.4310e-01],\n",
       "        [-7.2650e-02],\n",
       "        [-4.7927e-01],\n",
       "        [-3.1780e-01],\n",
       "        [-2.4409e-01],\n",
       "        [ 6.1162e-01],\n",
       "        [ 1.0902e-01],\n",
       "        [ 8.3321e-03],\n",
       "        [ 9.6121e-01],\n",
       "        [ 6.3865e-01],\n",
       "        [-8.1649e-01],\n",
       "        [ 3.6477e-01],\n",
       "        [-8.9391e-01],\n",
       "        [-1.4037e-01],\n",
       "        [-1.6938e-01],\n",
       "        [-9.3978e-01],\n",
       "        [-1.0534e-01],\n",
       "        [ 9.0191e-01],\n",
       "        [ 1.0797e-01],\n",
       "        [-4.5858e-01],\n",
       "        [ 3.9365e-01],\n",
       "        [-4.3191e-01],\n",
       "        [-4.7138e-01],\n",
       "        [-2.2707e-01],\n",
       "        [ 4.3691e-01],\n",
       "        [ 6.4505e-01],\n",
       "        [-6.9895e-01],\n",
       "        [ 5.6876e-01],\n",
       "        [ 5.2267e-01],\n",
       "        [-6.8013e-01],\n",
       "        [ 4.9438e-01],\n",
       "        [ 5.2174e-01],\n",
       "        [ 5.8567e-02],\n",
       "        [-4.7230e-01],\n",
       "        [ 7.6835e-01],\n",
       "        [ 5.4466e-01],\n",
       "        [ 9.3459e-01],\n",
       "        [ 9.9988e-01],\n",
       "        [-6.0489e-01],\n",
       "        [-9.1422e-04],\n",
       "        [-7.7769e-01],\n",
       "        [ 7.1428e-01],\n",
       "        [ 2.3983e-01],\n",
       "        [-4.2061e-01],\n",
       "        [-1.7521e-01],\n",
       "        [-8.2881e-01],\n",
       "        [-8.1009e-01],\n",
       "        [ 1.7338e-01],\n",
       "        [-6.8162e-01],\n",
       "        [ 1.0421e-01],\n",
       "        [-5.5166e-01],\n",
       "        [-2.0638e-01],\n",
       "        [ 8.3615e-01],\n",
       "        [-7.5951e-02],\n",
       "        [ 6.6441e-01],\n",
       "        [-9.5059e-01],\n",
       "        [ 6.8918e-01],\n",
       "        [-4.1803e-02],\n",
       "        [ 8.2755e-01],\n",
       "        [-9.7584e-01],\n",
       "        [ 4.5631e-01],\n",
       "        [ 6.9581e-01],\n",
       "        [-4.4177e-01],\n",
       "        [ 6.4733e-01],\n",
       "        [ 5.6934e-01],\n",
       "        [ 5.1005e-02],\n",
       "        [-4.8574e-01],\n",
       "        [-8.7569e-02],\n",
       "        [ 3.6354e-01],\n",
       "        [-1.6386e-01],\n",
       "        [ 7.4103e-01],\n",
       "        [-8.5627e-01],\n",
       "        [ 9.3451e-01],\n",
       "        [ 5.3252e-01],\n",
       "        [-2.6219e-01],\n",
       "        [-9.6810e-01],\n",
       "        [ 9.1786e-02],\n",
       "        [-8.0581e-01],\n",
       "        [-8.1674e-01],\n",
       "        [-1.6677e-01],\n",
       "        [-4.9397e-01],\n",
       "        [ 5.6320e-01],\n",
       "        [-9.9802e-01],\n",
       "        [ 8.2105e-01],\n",
       "        [ 8.3483e-01],\n",
       "        [ 6.2827e-01],\n",
       "        [-8.4676e-01],\n",
       "        [-9.5304e-01],\n",
       "        [-6.6560e-01],\n",
       "        [-5.6177e-01],\n",
       "        [-4.2780e-01],\n",
       "        [ 7.5067e-01],\n",
       "        [-5.1110e-01],\n",
       "        [ 4.0150e-01],\n",
       "        [-6.5554e-01],\n",
       "        [-9.3261e-01],\n",
       "        [-2.4611e-01],\n",
       "        [-6.9530e-01],\n",
       "        [-7.2104e-01],\n",
       "        [-5.9816e-01],\n",
       "        [-1.6914e-02],\n",
       "        [-5.0776e-01],\n",
       "        [ 3.2401e-01],\n",
       "        [ 4.9507e-01],\n",
       "        [ 6.1214e-01],\n",
       "        [ 6.7357e-01],\n",
       "        [ 1.9539e-01],\n",
       "        [-8.6088e-01],\n",
       "        [ 3.7174e-01],\n",
       "        [-7.8583e-01],\n",
       "        [ 1.1592e-01],\n",
       "        [-1.9714e-01],\n",
       "        [ 3.8759e-01],\n",
       "        [-7.7372e-01],\n",
       "        [-7.6976e-01],\n",
       "        [ 4.2678e-01],\n",
       "        [ 7.4022e-01],\n",
       "        [ 6.8270e-01],\n",
       "        [ 9.1979e-01],\n",
       "        [ 7.4579e-01],\n",
       "        [-2.0905e-01],\n",
       "        [ 7.5617e-01],\n",
       "        [ 8.1763e-01],\n",
       "        [ 8.7338e-01],\n",
       "        [ 1.4589e-01],\n",
       "        [ 1.2969e-02],\n",
       "        [-7.1343e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "b2bd959f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-397-0c51ce6de141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_by_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m_get_item_by_idx\u001b[0;34m(self, iterator, idx)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;34m\"\"\"Get the idx-th item of the iterator\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index {} is out of range'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for name, param in m.model.named_parameters():\n",
    "    param.copy_(m1.model[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "dbd14e5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-376-e2c4c0c9513f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "m.model[2].weight[0,0] = torch.nn.Parameter(torch(0))\n",
    "print(m.model[2].weight[0,0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e4ea55b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.nn at 0x7ff37019a390>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.combine_with_old(m2, decay_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "fd78e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06582815 , old =  0.06631946 , combined =  0.06582815\n"
     ]
    }
   ],
   "source": [
    "print(m1.model[2].weight[0,0].detach().numpy(), \", old = \", m2[2].weight[0,0].detach().numpy(),\n",
    "     \", combined = \", m1.model[2].weight[0,0].detach().numpy())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn()\n",
    "model.fit(val_x, val_y)\n",
    "yhat = model.pred(val_x)\n",
    "pd.DataFrame.from_dict({\"x\": [item[0] for item in val_x.tolist()],\n",
    "                        \"y\": val_y.tolist(),\n",
    "                       \"yhat\": [item[0] for item in yhat.tolist()]}).to_csv(working_path / \"subset_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba16486",
   "metadata": {},
   "source": [
    "### Combining two nn models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "e08df84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn():\n",
    "    \"\"\"\n",
    "    Neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs = 1, n_outputs = 2, H = 200):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_inputs, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, n_outputs),\n",
    "        )\n",
    "    def initialize(self, n_inputs = 1, n_outputs = 2, H = 200):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_inputs, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, n_outputs),\n",
    "        )\n",
    "        return self\n",
    "    def prepare_data(self, x, y):\n",
    "        if type(x) != torch.Tensor:\n",
    "            if len(x.shape) > 1:\n",
    "                x = torch.tensor(x[:, 1:]).float()\n",
    "            else:\n",
    "                x = torch.tensor(x).float()\n",
    "        if type(y) != torch.Tensor:\n",
    "            y = torch.tensor(y).float()\n",
    "        return x, y\n",
    "    def fit(self, x_train, y_train, loss_fn = torch.nn.MSELoss(), n_epochs = 10, lr = 1e-4):\n",
    "        model = self.model\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr = lr)\n",
    "        for epoch in range(n_epochs):\n",
    "            # get loss\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = self.model(x_train[:, np.newaxis])\n",
    "            loss = loss_fn(y_train, y_hat)\n",
    "\n",
    "            # update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return self\n",
    "            \n",
    "        return model\n",
    "    def evaluate(self, x_test, y_test, loss_fn = torch.nn.MSELoss()):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self.model(x_test[:, np.newaxis])\n",
    "            l = loss_fn(y_test, y_hat)\n",
    "        return l\n",
    "    def pred(self, x_new):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self.model(x_new)\n",
    "        return y_hat\n",
    "    def combine_with_old(self, model_old, decay_rate = .5):\n",
    "        for i in range(len(model_old)):\n",
    "            if \"weight\" in dir(model_old[i]):\n",
    "                self.model[i].weight = torch.nn.Parameter(decay_rate * model_old[i].weight + (1 - decay_rate) * self.model[i].weight)\n",
    "                self.model[i].bias = torch.nn.Parameter(decay_rate * model_old[i].bias + (1 - decay_rate) * self.model[i].bias)\n",
    "    def save(self, path = \".\", x_new = None, y_new = None, para = True):\n",
    "        x_new, y_new = self.prepare_data(x_new, y_new)\n",
    "        path = Path(path)\n",
    "        path.mkdir(parents = True, exist_ok = True)\n",
    "        y_hat = self.pred(x_new)\n",
    "        if not x_new is None:\n",
    "            pd.DataFrame.from_dict({\"x\": [item[0] for item in x_new.tolist()], \n",
    "                        \"y\": y_new,\n",
    "                        \"y_hat\": [item[0] for item in y_hat.tolist()]\n",
    "                       }).to_csv(path / Path(\"fitted.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "232fd4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "f, betas, zs = random_functions(args[\"n_tasks\"], 6,\n",
    "                                sigma_between = sigma_setting[s][0],\n",
    "                                sigma_within = sigma_setting[s][-1])\n",
    "result = []\n",
    "for i, fi in enumerate(f):\n",
    "    x = np.random.uniform(0, 1, 100)\n",
    "    result.append({\n",
    "        \"task\": i,\n",
    "        \"x\": x,\n",
    "        \"f\": fi(x),\n",
    "        \"y\": fi(x) + np.random.normal(0, .1, len(x))\n",
    "    })\n",
    "# save data\n",
    "data_df = pd.concat([pd.DataFrame(r) for r in result])\n",
    "data_df = data_df.reset_index()\n",
    "data_dict = data_df.to_dict(orient = \"list\")\n",
    "\n",
    "input_data = prepare_input(data_dict,\n",
    "                                   target_task = 5,\n",
    "                                   target_test_size = .4,\n",
    "                                  preprocess = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dde4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x, val_y = mod.prepare_data(input_data[\"X_target_val\"], input_data[\"y_target_val\"])\n",
    "\n",
    "# initialize model from target training data\n",
    "X_current, y_current = mod.prepare_data(input_data[\"X_target_train\"], input_data[\"y_target_train\"])\n",
    "mod.fit( X_current, y_current, n_epochs = 100, loss_fn = loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "769c4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = nn()\n",
    "m1.fit( X_current, y_current, n_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "3297c3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0622, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.model[2].weight[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "03d2f6e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.nn at 0x7f8251723828>"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = nn()\n",
    "m2.fit(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "e94894d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0445, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.model[2].weight[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "1024aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.combine_with_old(m2.model, decay_rate = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "7711ab77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0533, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.model[2].weight[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_selects = [None]\n",
    "# initialize hyperparameters\n",
    "alpha = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "beta = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "pi = dict.fromkeys(input_data[\"source_task\"], [0])\n",
    "\n",
    "mod = nn()\n",
    "val_x, val_y = mod.prepare_data(input_data[\"X_target_val\"], input_data[\"y_target_val\"])\n",
    "\n",
    "# initialize model from target training data\n",
    "X_current, y_current = mod.prepare_data(input_data[\"X_target_train\"], input_data[\"y_target_train\"])\n",
    "mod.fit( X_current, y_current, n_epochs = 100)\n",
    "l = mod.evaluate(val_x, val_y)\n",
    "losses = [l]\n",
    "model_old = copy.deepcopy(mod.model)\n",
    "\n",
    "for t in range(n_it):\n",
    "    # select bandit\n",
    "    bandit_current, pi = get_bandit(input_data, alpha, beta,t, pi)\n",
    "    bandit_selects.append(bandit_current)\n",
    "    \n",
    "    # set training data at this iteration\n",
    "    X_current, y_current, _ = subset_data(input_data[\"source_dict\"], \n",
    "                               key_value = bandit_current,\n",
    "                               key_name = \"task\", test_size = 0)\n",
    "    batch_id = random.choices(list(range(0, len(y_current))), k = batch_size)\n",
    "    X_current, y_current = X_current[batch_id, :], y_current[batch_id]\n",
    "\n",
    "    #X_current = np.concatenate((X_current, input_data[\"X_target_val\"]), axis = 0)\n",
    "    #y_current = np.concatenate((y_current, input_data[\"y_target_val\"]), axis = 0)\n",
    "    \n",
    "    X_current, y_current = mod.prepare_data(X_current, y_current)\n",
    "    # train model\n",
    "    #mod = model.initialize(n_inputs = 1)\n",
    "    mod = nn()\n",
    "    mod.fit(X_current, y_current, loss_fn = loss_fn, n_epochs = 200)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # combine parameters with previous model\n",
    "    #mod.combine_with_old(model_old, decay_rate = 1)\n",
    "    \n",
    "    # evaluate model\n",
    "    l = mod.evaluate(val_x, val_y, loss_fn = loss_fn)\n",
    "    losses += [l]\n",
    "    model_old = copy.deepcopy(mod.model)\n",
    "    print(t, \", current = \", mod.model[2].weight[0,0].detach().numpy(),\n",
    "          \", old = \", model_old[2].weight[0,0].detach().numpy())\n",
    "    # update bandit parameters\n",
    "    if conservative:\n",
    "        thres = 100000\n",
    "    else:\n",
    "        thres = avg_loss(bandit_selects, losses, bandit_current)\n",
    "    alpha, beta = update_hyper_para(alpha, beta, t, losses,\n",
    "                                    bandit_current,\n",
    "                                    thres = thres\n",
    "                                   )\n",
    "    mod.save(path = working_path / (\"current\" + str(t)), x_new = X_current, y_new = y_current, para = True)\n",
    "    mod.save(path = working_path / str(t), x_new = val_x, y_new = val_y, para = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
