{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ae08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9208f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5.0: [0.0, 11.0],\n",
       " 4.0: [1.0],\n",
       " 2.0: [2.0, 6.0, 12.0, 13.0, 14.0],\n",
       " 0.0: [3.0, 10.0],\n",
       " 3.0: [4.0, 7.0, 9.0],\n",
       " 1.0: [5.0, 8.0]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"~/Downloads/tasks.csv\")\n",
    "data_dict = data_df.to_dict()\n",
    "\n",
    "betas_df = pd.read_csv(\"~/Downloads/betas.csv\")\n",
    "\n",
    "d = dict.fromkeys(betas_df.cluster, [])\n",
    "for k, v in zip(betas_df.cluster, betas_df.task):\n",
    "    d[k] = d[k] +[v]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024d96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for k, v in my_dict.items():\n",
    "         if val in v:\n",
    "             return k\n",
    "    return \"There is no such key\"\n",
    "\n",
    "def subset_data(data_dict, key_value, key_name = \"task\", test_size = 0.33):\n",
    "    if type(data_dict[key_name]) == list:\n",
    "        values = data_dict[key_name]\n",
    "    else:\n",
    "        values = list(data_dict[key_name].values())\n",
    "        \n",
    "    if type(key_value) != list:\n",
    "        idx_task = np.where(np.array(values) == key_value)\n",
    "    else:\n",
    "        idx_task = [v in key_value for v in np.array(values)]\n",
    "        idx_task = np.where(np.array(idx_task) == True)\n",
    "    idx_task = idx_task[0].tolist()\n",
    "    x = [data_dict['x'][i] for i in idx_task]\n",
    "    tasks = [data_dict['task'][i] for i in idx_task]\n",
    "    X = np.array([np.ones(len(idx_task)), np.array(x)]).T\n",
    "    y = np.array([data_dict['y'][i] for i in idx_task])\n",
    "    if test_size == 0:\n",
    "        return X, y, tasks\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size = test_size,\n",
    "                                                        random_state = 123)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def mse(y_true, y_predict):\n",
    "    mse = np.mean((y_predict - y_true) ** 2)\n",
    "    return mse\n",
    "\n",
    "def prepare_input(data_dict, target_task, target_test_size ):\n",
    "    input_data = {\"data_dict\": data_dict}\n",
    "    input_data[\"X_target_train\"], input_data[\"X_target_test\"], input_data[\"y_target_train\"], input_data[\"y_target_test\"] = subset_data(data_dict, key_value = target_task, key_name = \"task\")\n",
    "    input_data[\"X_target_val\"], input_data[\"X_target_test\"], input_data[\"y_target_val\"], input_data[\"y_target_test\"] = train_test_split(input_data[\"X_target_test\"], input_data[\"y_target_test\"], \n",
    "                                                        test_size = target_test_size,\n",
    "                                                        random_state = 123)\n",
    "    \n",
    "    input_data[\"source_task\"] = list(set(list(itertools.chain.from_iterable(d.values()))) - set([target_task]))\n",
    "    \n",
    "    source_cluster = [get_key(d, i) for i in input_data[\"source_task\"]]\n",
    "    input_data[\"source_cluster\"] = list(set(source_cluster))\n",
    "    \n",
    "    idx_source = np.where(np.array(list(data_dict['task'].values())) != target_task)[0].tolist()\n",
    "    \n",
    "    # source data\n",
    "    input_data[\"source_dict\"] = {}\n",
    "    for key_name in data_dict.keys():\n",
    "        input_data[\"source_dict\"][key_name] = [data_dict[key_name][i] for i in idx_source]\n",
    "\n",
    "    \n",
    "    return(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654d442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add key \"cluster\" to `data_dict`\n",
    "data_dict[\"cluster\"] = []\n",
    "\n",
    "for task in data_dict[\"task\"].values():\n",
    "    cluster = get_key(d, task)\n",
    "    if(cluster == \"There is no such key\"):\n",
    "        print(\"task = \" + str(task))\n",
    "        break\n",
    "    data_dict[\"cluster\"].append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e69a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bandit(alpha, beta, t, pi, key_name = \"source_task\"):\n",
    "    source_cluster = alpha.keys()\n",
    "    for cluster in source_cluster:\n",
    "        if t == 0:\n",
    "            pi[cluster] = [np.random.beta(alpha[cluster][t], beta[cluster][t])]\n",
    "        else:\n",
    "            pi[cluster].append(np.random.beta(alpha[cluster][t], beta[cluster][t]))\n",
    "    pi_list = [pi[cluster][-1] for cluster in input_data[key_name]]\n",
    "    bandit = get_key(pi, max(pi_list))\n",
    "    return(bandit, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374e2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_hyper_para(alpha, beta, t, losses, bandit_current, thres = -1):\n",
    "    # for selected bandits\n",
    "    if losses[-1] < losses[-2]:\n",
    "    #if losses[-1] < np.mean(losses):\n",
    "    #if losses[-1] < np.quantile(losses, .25):\n",
    "        alpha[bandit_current] = alpha[bandit_current] + [alpha[bandit_current][-1] + 1]\n",
    "        beta[bandit_current] = beta[bandit_current] + [beta[bandit_current][-1]]\n",
    "    elif losses[-1] > thres:\n",
    "        alpha[bandit_current] = alpha[bandit_current] + [1]\n",
    "        beta[bandit_current] = beta[bandit_current] + [100]\n",
    "    else:\n",
    "        alpha[bandit_current]  = alpha[bandit_current] + [alpha[bandit_current][-1]]\n",
    "        beta[bandit_current] = beta[bandit_current] + [beta[bandit_current][-1] + 1]\n",
    "    # for unselected bandits\n",
    "    for bandit in alpha.keys():\n",
    "        if len(alpha[bandit]) < len(alpha[bandit_current]):#t + 2:\n",
    "           alpha[bandit] = alpha[bandit] + [alpha[bandit][-1]]\n",
    "           beta[bandit] = beta[bandit] + [beta[bandit][-1]]\n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4ee23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_ensemble(X_new, y_new, predict_old, predict_new, decay_rate):\n",
    "    pre1 = predict_old(X_new)\n",
    "    pre2 = predict_new(X_new)\n",
    "    return (1 - decay_rate) * pre1 + decay_rate * pre2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b41fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_loss(bandit_selects, losses, bandit_current):\n",
    "    j = 0\n",
    "    s = 0\n",
    "    for b, l in zip(bandit_selects, losses):\n",
    "        if (not b == bandit_current) and (not b is None):\n",
    "            s += l\n",
    "            j = j + 1\n",
    "    if j == 0:\n",
    "        return 100000\n",
    "    else:\n",
    "        return s/j    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae37567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandit_source_train(input_data, model, batch_size, decay_rate, n_it, loss):\n",
    "    bandit_selects = [None]\n",
    "    # initialize hyperparameters\n",
    "    alpha = dict.fromkeys(input_data[\"source_cluster\"], [1])\n",
    "    beta = dict.fromkeys(input_data[\"source_cluster\"], [1])\n",
    "    pi = dict.fromkeys(input_data[\"source_cluster\"], [0])\n",
    "    \n",
    "    # initialize model from target training data\n",
    "    mod_train = model.fit(input_data[\"X_target_train\"], input_data[\"y_target_train\"])\n",
    "    mod_pred = mod_train.predict(input_data[\"X_target_val\"])\n",
    "    losses = [loss(mod_pred, input_data[\"y_target_val\"])]\n",
    "    \n",
    "    \n",
    "    for t in range(n_it):\n",
    "        # select bandit\n",
    "        bandit_current, pi = get_bandit(alpha, beta,t, pi)\n",
    "        bandit_selects.append(bandit_current)\n",
    "        # set training data at this iteration\n",
    "        X_current, y_current,_ = subset_data(input_data[\"source_dict\"], \n",
    "                                   key_value = bandit_current,\n",
    "                                   key_name = \"cluster\", test_size = 0)\n",
    "        batch_id = random.choices(list(range(0, len(y_current))), k = batch_size)\n",
    "        X_current, y_current = X_current[batch_id, :], y_current[batch_id]\n",
    "        \n",
    "        X_current = np.concatenate((X_current, input_data[\"X_target_val\"]), axis = 0)\n",
    "        y_current = np.concatenate((y_current, input_data[\"y_target_val\"]), axis = 0)\n",
    "        \n",
    "        # train model\n",
    "        mod_old = mod_train\n",
    "        mod_train = model.fit(X_current, y_current)\n",
    "        mod_pred = pred_ensemble(input_data[\"X_target_val\"], input_data[\"X_target_val\"],\n",
    "                             mod_old.predict, mod_train.predict, decay_rate)\n",
    "        \n",
    "        # evaluate model\n",
    "        l = loss(input_data[\"y_target_val\"], mod_pred)\n",
    "        losses += [l]\n",
    "        \n",
    "        \n",
    "        # update bandit parameters \n",
    "        thres = avg_loss(bandit_selects, losses, bandit_current)\n",
    "        alpha, beta = update_hyper_para(alpha, beta, t, losses,\n",
    "                                        bandit_current,\n",
    "                                        thres = thres\n",
    "                                       )\n",
    "    return losses, alpha, beta, bandit_selects, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3de766e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(input_data, pi, N, model, pred_ensemble, loss):\n",
    "    final_loss = dict.fromkeys([\"bandit\", \"all_source\", \"target_train\", \"random_source\"], [])\n",
    "    # weighted all source, by bandit selection parameters\n",
    "    X_end, y_end, tasks = subset_data(input_data[\"data_dict\"], key_value = input_data[\"source_task\"], key_name = \"task\", test_size = 0)\n",
    "    mod_train = model.fit(X_end, y_end, [pi[t][-1] for t in tasks])\n",
    "    mod_pred = pred_ensemble(input_data[\"X_target_test\"], input_data[\"X_target_test\"],\n",
    "                                 mod_train.predict, mod_train.predict, decay_rate = 1)\n",
    "    final_loss[\"bandit\"] = [loss(input_data[\"y_target_test\"], mod_pred)]\n",
    "    # All source\n",
    "    mod_train = model.fit(X_end, y_end)\n",
    "    mod_pred = pred_ensemble(input_data[\"X_target_test\"], input_data[\"X_target_test\"],\n",
    "                                 mod_train.predict, mod_train.predict, decay_rate = 1)\n",
    "    final_loss[\"all_source\"] = [loss(input_data[\"y_target_test\"], mod_pred)]\n",
    "    # target train\n",
    "    mod_train = model.fit(input_data[\"X_target_train\"], input_data[\"y_target_train\"])\n",
    "    mod_pred = pred_ensemble(input_data[\"X_target_test\"], input_data[\"X_target_test\"],\n",
    "                                 mod_train.predict, mod_train.predict, decay_rate = 1)\n",
    "    final_loss[\"target_train\"] =[ loss(input_data[\"y_target_test\"], mod_pred)]\n",
    "\n",
    "    # One random source\n",
    "    for n in range(N):\n",
    "        # one random source\n",
    "        X_random, y_random, _ = subset_data(input_data[\"data_dict\"],\n",
    "                                            key_value = random.choice(input_data[\"source_task\"]),\n",
    "                                            key_name = \"task\", test_size = 0)\n",
    "\n",
    "\n",
    "        mod_train = model.fit(X_random, y_random)\n",
    "        mod_pred = pred_ensemble(input_data[\"X_target_test\"], input_data[\"X_target_test\"],\n",
    "                                     mod_train.predict, mod_train.predict, decay_rate = 1)\n",
    "        final_loss[\"random_source\"] = final_loss[\"random_source\"] + [loss(input_data[\"y_target_test\"], mod_pred)]\n",
    "    final_loss[\"random_source\"] = [np.mean(final_loss[\"random_source\"])]\n",
    "    \n",
    "    return(final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fedd6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandit_source_train(input_data, model, batch_size, decay_rate, n_it, loss):\n",
    "    bandit_selects = [None]\n",
    "    # initialize hyperparameters\n",
    "    alpha = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "    beta = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "    pi = dict.fromkeys(input_data[\"source_task\"], [0])\n",
    "    \n",
    "    # initialize model from target training data\n",
    "    mod_train = model.fit(input_data[\"X_target_train\"], input_data[\"y_target_train\"])\n",
    "    mod_pred = mod_train.predict(input_data[\"X_target_val\"])\n",
    "    losses = [loss(mod_pred, input_data[\"y_target_val\"])]\n",
    "    \n",
    "    \n",
    "    for t in range(n_it):\n",
    "        # select bandit\n",
    "        bandit_current, pi = get_bandit(alpha, beta,t, pi)\n",
    "        bandit_selects.append(bandit_current)\n",
    "        # set training data at this iteration\n",
    "        X_current, y_current, _ = subset_data(input_data[\"source_dict\"], \n",
    "                                   key_value = bandit_current,\n",
    "                                   key_name = \"task\", test_size = 0)\n",
    "        batch_id = random.choices(list(range(0, len(y_current))), k = batch_size)\n",
    "        X_current, y_current = X_current[batch_id, :], y_current[batch_id]\n",
    "        \n",
    "        X_current = np.concatenate((X_current, input_data[\"X_target_val\"]), axis = 0)\n",
    "        y_current = np.concatenate((y_current, input_data[\"y_target_val\"]), axis = 0)\n",
    "        \n",
    "        # train model\n",
    "        mod_old = mod_train\n",
    "        mod_train = model.fit(X_current, y_current)\n",
    "        mod_pred = pred_ensemble(input_data[\"X_target_val\"], input_data[\"X_target_val\"],\n",
    "                             mod_old.predict, mod_train.predict, decay_rate)\n",
    "        \n",
    "        # evaluate model\n",
    "        l = loss(input_data[\"y_target_val\"], mod_pred)\n",
    "        losses += [l]\n",
    "        \n",
    "        \n",
    "        # update bandit parameters \n",
    "        thres = avg_loss(bandit_selects, losses, bandit_current)\n",
    "        alpha, beta = update_hyper_para(alpha, beta, t, losses,\n",
    "                                        bandit_current,\n",
    "                                        thres = thres\n",
    "                                       )\n",
    "    # baseline   \n",
    "    _, prob = get_bandit(alpha, beta,t, pi)\n",
    "    #bandit_weights = prob\n",
    "    #prob = list(pi.values())\n",
    "    #prob = list(np.concatenate(prob).flat)\n",
    "    bl = baseline(input_data, prob, N = 10, model = model, pred_ensemble = pred_ensemble)\n",
    "    bandit_weights = [prob[bd][-1] for bd in list(prob.keys())]\n",
    "    \n",
    "    return losses, alpha, beta, bandit_selects, pi, bl, bandit_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcd43ad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-66861403216b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_test_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     losses, alpha, beta, bandit_selects, pi, bl, bandit_weights = bandit_source_train(input_data, model = LinearRegression(), batch_size = 8,\n\u001b[0;32m----> 5\u001b[0;31m                                                   decay_rate = 1, n_it = 100, loss = mse)\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./derived_data/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"target_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_task\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1c743a511b3c>\u001b[0m in \u001b[0;36mbandit_source_train\u001b[0;34m(input_data, model, batch_size, decay_rate, n_it, loss)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#prob = list(pi.values())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m#prob = list(np.concatenate(prob).flat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_ensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_ensemble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mbandit_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-3f69822fef3f>\u001b[0m in \u001b[0;36mbaseline\u001b[0;34m(input_data, pi, N, model, pred_ensemble)\u001b[0m\n\u001b[1;32m      6\u001b[0m     mod_pred = pred_ensemble(input_data[\"X_target_test\"], input_data[\"X_target_test\"],\n\u001b[1;32m      7\u001b[0m                                  mod_train.predict, mod_train.predict, decay_rate = 1)\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfinal_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bandit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y_target_test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# All source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmod_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "for target_task in range(len(d.keys())):\n",
    "    target_test_size = 0.9\n",
    "    input_data = prepare_input(data_dict, target_task = target_task, target_test_size = target_test_size)\n",
    "    losses, alpha, beta, bandit_selects, pi, bl, bandit_weights = bandit_source_train(input_data, model = LinearRegression(), batch_size = 8,\n",
    "                                                  decay_rate = 1, n_it = 100, loss = mse)\n",
    "    output_dir = \"./derived_data/\" + \"target_\" + str(target_task) + \"_\" + str(target_test_size) + \"/\"\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    pd.DataFrame.from_dict(alpha).to_csv(output_dir + \"alpha.csv\")\n",
    "    pd.DataFrame.from_dict(beta).to_csv(output_dir + \"beta.csv\")\n",
    "    pd.DataFrame.from_dict({\"losses\": losses, \"bandit_selects\": bandit_selects}).to_csv(output_dir + \"losses.csv\")\n",
    "    pd.DataFrame.from_dict(pi).to_csv(output_dir + \"pi.csv\")\n",
    "    pd.DataFrame.from_dict(bl).to_csv(output_dir + \"baseline.csv\")\n",
    "    pd.DataFrame.from_dict(bandit_weights).to_csv(output_dir + \"bandit_weights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce50f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
