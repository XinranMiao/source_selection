{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09ae08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9208f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"~/Downloads/tasks.csv\")\n",
    "data_dict = data_df.to_dict()\n",
    "\n",
    "betas_df = pd.read_csv(\"~/Downloads/betas.csv\")\n",
    "\n",
    "d = dict.fromkeys(betas_df.cluster, [])\n",
    "for k, v in zip(betas_df.cluster, betas_df.task):\n",
    "    d[k] = d[k] +[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "024d96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for k, v in my_dict.items():\n",
    "         if val in v:\n",
    "             return k\n",
    "    return \"There is no such key\"\n",
    "\n",
    "def subset_data(data_dict, key_value, key_name = \"task\", test_size = 0.33):\n",
    "    if type(data_dict[key_name]) == list:\n",
    "        values = data_dict[key_name]\n",
    "    else:\n",
    "        values = list(data_dict[key_name].values())\n",
    "    idx_task = np.where(np.array(values) == key_value)\n",
    "    idx_task = idx_task[0].tolist()\n",
    "    x = [data_dict['x'][i] for i in idx_task]\n",
    "    X = np.array([np.ones(len(idx_task)), np.array(x)]).T\n",
    "    y = np.array([data_dict['y'][i] for i in idx_task])\n",
    "    if test_size == 0:\n",
    "        return X, y\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size = test_size,\n",
    "                                                        random_state = 123)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def mse(model, X_true, y_true):\n",
    "    y_predict = model.predict(X_true)\n",
    "    mse = np.mean((y_predict - y_true) ** 2)\n",
    "    return mse\n",
    "\n",
    "def prepare_input(data_dict, target_task):\n",
    "    input_data = {\"data_dict\": data_dict}\n",
    "    input_data[\"X_target_train\"], input_data[\"X_target_test\"], input_data[\"y_target_train\"], input_data[\"y_target_test\"] = subset_data(data_dict, key_value = target_task, key_name = \"task\")\n",
    "    input_data[\"X_target_val\"], input_data[\"X_target_test\"], input_data[\"y_target_val\"], input_data[\"y_target_test\"] = train_test_split(input_data[\"X_target_test\"], input_data[\"y_target_test\"], \n",
    "                                                        test_size = 0.5,\n",
    "                                                        random_state = 123)\n",
    "    \n",
    "    input_data[\"source_task\"] = list(set(list(itertools.chain.from_iterable(d.values()))) - set([target_task]))\n",
    "    \n",
    "    source_cluster = [get_key(d, i) for i in input_data[\"source_task\"]]\n",
    "    input_data[\"source_cluster\"] = list(set(source_cluster))\n",
    "    \n",
    "    idx_source = np.where(np.array(list(data_dict['task'].values())) != target_task)[0].tolist()\n",
    "    \n",
    "    # source data\n",
    "    input_data[\"source_dict\"] = {}\n",
    "    for key_name in data_dict.keys():\n",
    "        input_data[\"source_dict\"][key_name] = [data_dict[key_name][i] for i in idx_source]\n",
    "\n",
    "    \n",
    "    return(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "654d442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add key \"cluster\" to `data_dict`\n",
    "data_dict[\"cluster\"] = []\n",
    "\n",
    "for task in data_dict[\"task\"].values():\n",
    "    cluster = get_key(d, task)\n",
    "    if(cluster == \"There is no such key\"):\n",
    "        print(\"task = \" + str(task))\n",
    "        break\n",
    "    data_dict[\"cluster\"].append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50e69a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bandit(alpha, beta, t, pi):\n",
    "    source_cluster = alpha.keys()\n",
    "    for cluster in source_cluster:\n",
    "        if t == 0:\n",
    "            pi[cluster] = [np.random.beta(alpha[cluster][t], beta[cluster][t])]\n",
    "        else:\n",
    "            pi[cluster].append(np.random.beta(alpha[cluster][t], beta[cluster][t]))\n",
    "    pi_list = [pi[cluster][t] for cluster in input_data[\"source_cluster\"]]\n",
    "    bandit = get_key(pi, max(pi_list))\n",
    "    return(bandit, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "374e2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_hyper_para(alpha, beta, t, evaluation, bandit_current):\n",
    "    # for selected bandits\n",
    "    if evaluation[-1] > evaluation[-2]:\n",
    "        alpha[bandit_current] = alpha[bandit_current] + [alpha[bandit_current][t] + 2]\n",
    "        beta[bandit_current] = beta[bandit_current] + [beta[bandit_current][t]]\n",
    "    else:\n",
    "        alpha[bandit_current]  = alpha[bandit_current] + [alpha[bandit_current][t]]\n",
    "        beta[bandit_current] = beta[bandit_current] + [beta[bandit_current][t] + 2]\n",
    "    # for unselected bandits\n",
    "    for bandit in alpha.keys():\n",
    "        if len(alpha[bandit]) < t + 2:\n",
    "           alpha[bandit] = alpha[bandit] + [alpha[bandit][t]]\n",
    "           beta[bandit] = beta[bandit] + [beta[bandit][t]]\n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae37567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandit_source_train(input_data, model, batch_size, decay_rate, n_it, metric):\n",
    "    \n",
    "    # initialize hyperparameters\n",
    "    alpha = beta = dict.fromkeys(input_data[\"source_cluster\"], [1])\n",
    "    pi = dict.fromkeys(input_data[\"source_cluster\"], [0])\n",
    "    \n",
    "    # initialize model from target training data\n",
    "    mod_train = model.fit(input_data[\"X_target_train\"], input_data[\"y_target_train\"])\n",
    "    evaluation = [metric(mod_train, input_data[\"X_target_val\"], input_data[\"y_target_val\"])]\n",
    "    \n",
    "    \n",
    "    for t in range(n_it):\n",
    "        # select bandit\n",
    "        bandit_current, pi = get_bandit(alpha, beta,t, pi)\n",
    "        \n",
    "        # set training data at this iteration\n",
    "        X_current, y_current = subset_data(input_data[\"source_dict\"], \n",
    "                                   key_value = bandit_current,\n",
    "                                   key_name = \"cluster\", test_size = 0)\n",
    "        batch_id = random.choices(list(range(0, len(y_current))), k = batch_size)\n",
    "        X_current, y_current = X_current[batch_id, :], y_current[batch_id]\n",
    "        \n",
    "        X_current = np.concatenate((X_current, input_data[\"X_target_val\"]), axis = 0)\n",
    "        y_current = np.concatenate((y_current, input_data[\"y_target_val\"]), axis = 0)\n",
    "        \n",
    "        # train model\n",
    "        mod_train = model.fit(X_current, y_current)\n",
    "        # evaluate model\n",
    "        evaluation += [metric(mod_train, input_data[\"X_target_val\"], input_data[\"y_target_val\"])]\n",
    "        \n",
    "        # update bandit parameters \n",
    "        alpha, beta = update_hyper_para(alpha, beta, t, evaluation, bandit_current)\n",
    "    \n",
    "    return evaluation, alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d08e9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = prepare_input(data_dict, target_task = 2)\n",
    "evaluation, alpha, beta = bandit_source_train(input_data, model = LinearRegression(), batch_size = 8,\n",
    "                    decay_rate = 0, n_it = 100, metric = mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf1316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
