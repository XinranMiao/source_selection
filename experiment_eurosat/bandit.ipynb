{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a296089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca6210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import collections\n",
    "\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e367f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "EuroSat_Type = 'ALL'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8768cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = str(sys.argv)\n",
    "target_task = args[1]\n",
    "algorithm = args[2]\n",
    "algorithm = \"bandit\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d15f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_task = \"France\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27645bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "output_path = Path(\"derived_data\")\n",
    "output_path.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9043dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EuroSat_Type == 'RGB':\n",
    "  data_folder = '/content/sample_data/'\n",
    "  #root = os.path.join(data_folder, '2750/')\n",
    "  root = '2750/'\n",
    "  download_ON = os.path.exists(root)\n",
    "\n",
    "  if not download_ON:\n",
    "    # This can be long...\n",
    "    #os.chdir(data_folder)\n",
    "    os.system('wget http://madm.dfki.de/files/sentinel/EuroSAT.zip') #Just RGB Bands\n",
    "    !unzip EuroSAT.zip\n",
    "    download_ON = True\n",
    "elif EuroSat_Type == 'ALL':\n",
    "    root = 'ds/images/remote_sensing/otherDatasets/sentinel_2/tif/'\n",
    "    download_ON = os.path.exists(root)\n",
    "    if not download_ON:\n",
    "      os.system('wget http://madm.dfki.de/files/sentinel/EuroSATallBands.zip') #All bands\n",
    "      !unzip EuroSATallBands.zip\n",
    "      download_ON = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a5f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = pd.read_csv(\"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55ad5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.DatasetFolder(root=root,loader = iloader, transform=None, extensions = 'tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "528edc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = prepare_input_data(geo_df, target_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c51c7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f9baf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_, val_, criterion, optimizer, epochs=None, scheduler=None, weights=None, save_epoch = 10,\n",
    "plot = False):\n",
    "    losses=[]; acc=[]; mean_losses=[]; val_acc=[]\n",
    "    iter_ = t0 =0\n",
    "    t0 = time.time()\n",
    "    for e in range(1, epochs + 1):\n",
    "        print('e=',e,'{} seconds'.format(time.time() - t0))\n",
    "        net.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_):\n",
    "            if torch.cuda.is_available():\n",
    "                data, target =  cus_aug(Variable(data.cuda())), Variable(target.cuda())\n",
    "            else:\n",
    "                data, target =  cus_aug(Variable(data)), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses = np.append(losses,loss.item())\n",
    "            mean_losses = np.append(mean_losses, np.mean(losses[max(0,iter_-100):iter_]))\n",
    "            if iter_ % 500 == 0: #printing after 600 epochs\n",
    "                clear_output()\n",
    "                print('Iteration Number',iter_,'{} seconds'.format(time.time() - t0))\n",
    "                t0 = time.time()\n",
    "                pred = output.data.cpu().numpy()#[0]\n",
    "                pred=sigmoid(pred)\n",
    "                gt = target.data.cpu().numpy()#[0]\n",
    "                acc = np.append(acc,accuracy(gt,pred))\n",
    "                val_acc = np.append(val_acc,validation(net, val_))\n",
    "                print('Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}\\tLearning Rate:{}'.format(\n",
    "                    e, epochs, batch_idx, len(train_),\n",
    "                    100. * batch_idx / len(train_), loss.item(), acc[-1],optimizer.param_groups[0]['lr']))\n",
    "                if plot is True:\n",
    "                    plt.plot(mean_losses) and plt.show()\n",
    "                    plt.plot( range(len(acc)) ,acc,'b',label = 'training')\n",
    "                    plt.plot( range(len(val_acc)), val_acc,'r--',label = 'validation')\n",
    "                    plt.legend() and plt.show()\n",
    "                    print('validation accuracy : {}'.format(val_acc[-1]))\n",
    "                \n",
    "                #print(mylabels[np.where(gt[1,:])[0]])\n",
    "            iter_ += 1\n",
    "            \n",
    "            del(data, target, loss)\n",
    "        if scheduler is not None:\n",
    "           scheduler.step()\n",
    "        if e % save_epoch == 0:\n",
    "            \n",
    "            torch.save(net.state_dict(), '.\\Eurosat{}'.format(e))\n",
    "    print('validation accuracy : {}'.format(val_acc[-1]))\n",
    "    return net, val_acc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d32570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandit_selection(data, input_data, n_epochs = 3, n_it = 2, algorithm = \"bandit\",iter_samples = 160,\n",
    "                     lr = .01, milestones = milestones,\n",
    "                     criteria = criteria, output_path = \".\"):\n",
    "    # prepare data ---\n",
    "    \n",
    "    target_val_loader =  torch.utils.data.DataLoader(torch.utils.data.Subset(data, input_data[\"idx_val\"]), \n",
    "                                                  batch_size = 16, shuffle = True, num_workers = 0)\n",
    "    target_train_loader =  torch.utils.data.DataLoader(torch.utils.data.Subset(data, input_data[\"idx_train\"]), \n",
    "                                                      batch_size = 16, shuffle = True, num_workers = 0)\n",
    "    target_test_loader =  torch.utils.data.DataLoader(torch.utils.data.Subset(data, input_data[\"idx_test\"]), \n",
    "                                                      batch_size = 16, shuffle = True, num_workers = 0)\n",
    "    \n",
    "\n",
    "    \n",
    "    # initialize hyperparameters ---\n",
    "    \n",
    "    bandit_selects = [None]\n",
    "    alpha = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "    beta = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "    pi = dict.fromkeys(input_data[\"source_task\"], [0])\n",
    "    \n",
    "    \n",
    "    # initialize model ---\n",
    "   \n",
    "    net = Load_model()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones = milestones, gamma=0.1)\n",
    "    if torch.cuda.is_available():\n",
    "        net=net.cuda()\n",
    "\n",
    "    net, acc = train(net, target_train_loader , target_test_loader , criteria, optimizer, n_epochs, scheduler)\n",
    "    print(\"Model initiated with acc \", acc)\n",
    "    accs = [acc]\n",
    "    \n",
    "    # train ---\n",
    "    \n",
    "    for t in range(n_it):\n",
    "        if algorithm == \"bandit\":\n",
    "            bandit_current, pi = get_bandit(input_data, alpha, beta,t, pi)\n",
    "            bandit_selects.append(bandit_current)\n",
    "            current_id = [input_data[\"source_dict\"][\"id\"][i] for (i, v) in enumerate(input_data[\"source_dict\"]['country']) if v == bandit_current]\n",
    "            current_id = random.choices(current_id, k = iter_samples)\n",
    "        else:\n",
    "            current_id = random.sample(input_data[\"idx_source\"], k = iter_samples)\n",
    "        current_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(data, input_data[\"idx_test\"]), \n",
    "                                                          batch_size = 16, shuffle = True, num_workers = 0)\n",
    "        net, acc = train(net, current_loader, target_test_loader , criteria, optimizer, n_epochs, scheduler)\n",
    "\n",
    "        print(\"At iteration \", t, \", source country is \", bandit_current, \", acc is \", acc, \"-------\\n\")\n",
    "\n",
    "        accs += [acc]\n",
    "        if algorithm == \"bandit\":\n",
    "            alpha, beta = update_hyper_para(alpha, beta, t, accs,\n",
    "                                            bandit_current\n",
    "                                           )\n",
    "        if not output_path is None:\n",
    "            if t % 1 == 0:\n",
    "                torch.save(net.state_dict(), output_path / Path(input_data[\"target_task\"] + \"_\" + algorithm + \".pt\" ))\n",
    "    if not output_path is None:\n",
    "        save_output(output_path / Path(input_data[\"target_task\"] + \"_\" + algorithm + \"_evaluation.csv\" ), accs, accs)\n",
    "    return net, bandit_selects, accs, alpha, beta, pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc04a539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Patron/Desktop/source_selection/experiment_eurosat/dataset.py:92: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Number 0 1.8680260181427002 seconds\n",
      "Train (epoch 1/1) [0/10 (0%)]\tLoss: 1.679871\tAccuracy: 0.5\tLearning Rate:0.01\n",
      "validation accuracy : 0.25\n",
      "At iteration  1 , source country is  Moldova , acc is  0.25 -------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, bandit_selects, accs, alpha, beta, pi = bandit_selection(data, input_data, \n",
    "                                                            n_epochs = 1, n_it = 2,\n",
    "                                                            algorithm = algorithm, iter_samples = 160,\n",
    "                                                           output_path = output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
