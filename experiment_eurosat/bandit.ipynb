{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a296089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ca6210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import collections\n",
    "\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2e367f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "EuroSat_Type = 'ALL'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8768cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = str(sys.argv)\n",
    "target_task = args[1]\n",
    "algorithm = args[2]\n",
    "algorithm = \"bandit\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05d15f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_task = \"France\"\n",
    "target_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27645bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "output_path = Path(\"derived_data\")\n",
    "output_path.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f9043dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EuroSat_Type == 'RGB':\n",
    "  data_folder = '/content/sample_data/'\n",
    "  #root = os.path.join(data_folder, '2750/')\n",
    "  root = '2750/'\n",
    "  download_ON = os.path.exists(root)\n",
    "\n",
    "  if not download_ON:\n",
    "    # This can be long...\n",
    "    #os.chdir(data_folder)\n",
    "    os.system('wget http://madm.dfki.de/files/sentinel/EuroSAT.zip') #Just RGB Bands\n",
    "    !unzip EuroSAT.zip\n",
    "    download_ON = True\n",
    "elif EuroSat_Type == 'ALL':\n",
    "    root = 'ds/images/remote_sensing/otherDatasets/sentinel_2/tif/'\n",
    "    download_ON = os.path.exists(root)\n",
    "    if not download_ON:\n",
    "      os.system('wget http://madm.dfki.de/files/sentinel/EuroSATallBands.zip') #All bands\n",
    "      !unzip EuroSATallBands.zip\n",
    "      download_ON = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98a5f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = pd.read_csv(\"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55ad5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.DatasetFolder(root=root,loader = iloader, transform = None, extensions = 'tif')\n",
    "labels = [v[1] for (i, v) in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73924f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_data(geo_df, target_task, labels = None, \n",
    "                       train_size = .6, test_size = .5, target_size = 1600):\n",
    "    \n",
    "    geo_dict = geo_df.to_dict()\n",
    "    countries = list(set(geo_dict[\"country\"].values()))\n",
    "    countries = [x for x in countries if str(x) != \"nan\"]\n",
    "    id_countries = dict.fromkeys(countries)\n",
    "    for k in id_countries.keys():\n",
    "        id_countries[k] = [v for (i, v) in enumerate(geo_dict[\"id\"]) if geo_dict[\"country\"][i] == k]\n",
    "\n",
    "    # create a dictionary for input data\n",
    "    \n",
    "    input_data = {\n",
    "        \"source_task\": list(set(id_countries.keys()) - set(target_task)),\n",
    "        \"target_task\": target_task\n",
    "    }\n",
    "\n",
    "    \n",
    "    # all data, both source and target\n",
    "    \n",
    "    input_data[\"data_dict\"] = {}\n",
    "    for k in geo_dict.keys():\n",
    "        input_data[\"data_dict\"][k] = [geo_dict[k][i] for (i, v) in enumerate(geo_dict[\"country\"].values()) if str(v) != \"nan\"]\n",
    "\n",
    "\n",
    "        \n",
    "    # split indices for source and target\n",
    "    \n",
    "    input_data[\"idx_source\"] = [i for (i, v) in enumerate(input_data[\"data_dict\"]['country']) if v != input_data[\"target_task\"]]\n",
    "    input_data[\"idx_target\"] = [i for (i, v) in enumerate(input_data[\"data_dict\"]['country']) if v == input_data[\"target_task\"]]\n",
    "\n",
    "    target_labels = list(set([labels[i] for i in input_data[\"idx_target\"]]))\n",
    "\n",
    "    \n",
    "    # For source data, create a dictionary to record the countries\n",
    "    \n",
    "    input_data[\"source_dict\"] = {}\n",
    "    for k in geo_dict.keys():\n",
    "        input_data[\"source_dict\"][k] = [input_data[\"data_dict\"][k][i] for i in input_data[\"idx_source\"] if labels[i] in target_labels]\n",
    "\n",
    "   \n",
    "    # resample the target to make the number of samples is fixed\n",
    "    \n",
    "    if len(input_data[\"idx_target\"]) >= target_size:\n",
    "        input_data[\"idx_target\"] = random.sample(input_data[\"idx_target\"], k = target_size)\n",
    "    else:\n",
    "        input_data[\"idx_target\"] = random.choices(input_data[\"idx_target\"], k = target_size)\n",
    "        \n",
    "    \n",
    "    # split the target data into train / validation / test sets\n",
    "    \n",
    "    y_target = [labels[i] for i in input_data[\"idx_target\"]]\n",
    "    input_data[\"idx_train\"], idx_rest, _, y_rest = train_test_split(input_data[\"idx_target\"],\n",
    "                                                              y_target,\n",
    "                                                              test_size = 1 - train_size,\n",
    "                                                              random_state = 0, shuffle = True)\n",
    "    input_data[\"idx_val\"], input_data[\"idx_test\"], _, _ = train_test_split(idx_rest,\n",
    "                                                              y_rest,\n",
    "                                                              test_size = test_size,\n",
    "                                                              random_state = 0, shuffle = True)\n",
    "\n",
    "    return input_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d695275",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = prepare_input_data(geo_df, target_task, labels = labels,\n",
    "                               target_size = target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c51c7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db5ad7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data ---\n",
    "\n",
    "target_val_loader =  torch.utils.data.DataLoader(torch.utils.data.Subset(data, input_data[\"idx_val\"]), \n",
    "                                              batch_size = 16, shuffle = True, num_workers = 0)\n",
    "target_train_loader =  torch.utils.data.DataLoader(torch.utils.data.Subset(data, input_data[\"idx_train\"]), \n",
    "                                                  batch_size = 16, shuffle = True, num_workers = 0)\n",
    "target_test_loader =  torch.utils.data.DataLoader(torch.utils.data.Subset(data, input_data[\"idx_test\"]), \n",
    "                                                  batch_size = 16, shuffle = True, num_workers = 0)\n",
    "\n",
    "\n",
    "\n",
    "# initialize hyperparameters ---\n",
    "\n",
    "bandit_selects = [None]\n",
    "alpha = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "beta = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "pi = dict.fromkeys(input_data[\"source_task\"], [0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc04a539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miaoxinran/Desktop/source_selection/experiment_eurosat/dataset.py:92: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration  1 , source country is  BelgiÃ« / Belgique / Belgien , acc is  0.28125\n"
     ]
    }
   ],
   "source": [
    "_, bandit_selects, accs, alpha, beta, pi = bandit_selection(data, input_data, \n",
    "                                                            n_epochs = 1, n_it = 2,\n",
    "                                                            algorithm = algorithm, iter_samples = 160,\n",
    "                                                           output_path = output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
