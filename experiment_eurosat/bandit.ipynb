{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a296089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca6210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import collections\n",
    "\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e367f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "EuroSat_Type = 'ALL'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8768cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = str(sys.argv)\n",
    "target_task = args[1]\n",
    "algorithm = args[2]\n",
    "algorithm = \"bandit\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d15f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_task = 1#\"Moldova\"\n",
    "target_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27645bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "output_path = Path(\"derived_data\")\n",
    "output_path.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9043dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EuroSat_Type == 'RGB':\n",
    "  data_folder = '/content/sample_data/'\n",
    "  #root = os.path.join(data_folder, '2750/')\n",
    "  root = '2750/'\n",
    "  download_ON = os.path.exists(root)\n",
    "\n",
    "  if not download_ON:\n",
    "    # This can be long...\n",
    "    #os.chdir(data_folder)\n",
    "    os.system('wget http://madm.dfki.de/files/sentinel/EuroSAT.zip') #Just RGB Bands\n",
    "    !unzip EuroSAT.zip\n",
    "    download_ON = True\n",
    "elif EuroSat_Type == 'ALL':\n",
    "    root = 'ds/images/remote_sensing/otherDatasets/sentinel_2/tif/'\n",
    "    download_ON = os.path.exists(root)\n",
    "    if not download_ON:\n",
    "      os.system('wget http://madm.dfki.de/files/sentinel/EuroSATallBands.zip') #All bands\n",
    "      !unzip EuroSATallBands.zip\n",
    "      download_ON = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a5f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = pd.read_csv(\"metadata_clustered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55ad5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.DatasetFolder(root=root,loader = iloader, transform = None, extensions = 'tif')\n",
    "labels = [v[1] for (i, v) in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e55a7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_data(geo_df, target_task, group_by = \"country\",\n",
    "                       labels = None, \n",
    "                       train_size = 320, test_size = 320, target_size = 1600):\n",
    "    \n",
    "    geo_dict = geo_df.to_dict()\n",
    "    groups = list(set(geo_dict[group_by].values()))\n",
    "    groups = [x for x in groups if str(x) != \"nan\"]\n",
    "    id_groups = dict.fromkeys(groups)\n",
    "    for k in id_groups.keys():\n",
    "        id_groups[k] = [v for (i, v) in enumerate(geo_dict[\"id\"]) if geo_dict[group_by][i] == k]\n",
    "\n",
    "    # create a dictionary for input data\n",
    "    \n",
    "    input_data = {\n",
    "        \"source_task\": list(set(id_groups.keys()) - set([target_task])),\n",
    "        \"target_task\": target_task\n",
    "    }\n",
    "\n",
    "    \n",
    "    # all data, both source and target\n",
    "    \n",
    "    input_data[\"data_dict\"] = {}\n",
    "    for k in geo_dict.keys():\n",
    "        input_data[\"data_dict\"][k] = [geo_dict[k][i] for (i, v) in enumerate(geo_dict[group_by].values()) if str(v) != \"nan\"]\n",
    "\n",
    "\n",
    "        \n",
    "    # split indices for source and target\n",
    "    \n",
    "    input_data[\"idx_source\"] = [i for (i, v) in enumerate(input_data[\"data_dict\"][group_by]) if v != input_data[\"target_task\"]]\n",
    "    input_data[\"idx_target\"] = [i for (i, v) in enumerate(input_data[\"data_dict\"][group_by]) if v == input_data[\"target_task\"]]\n",
    "\n",
    "    target_labels = list(set([labels[i] for i in input_data[\"idx_target\"]]))\n",
    "\n",
    "    \n",
    "    # For source data, create a dictionary to record the countries\n",
    "    \n",
    "    input_data[\"source_dict\"] = {}\n",
    "    for k in geo_dict.keys():\n",
    "        input_data[\"source_dict\"][k] = [input_data[\"data_dict\"][k][i] for i in input_data[\"idx_source\"] if labels[i] in target_labels]\n",
    "    \n",
    "    # rewrite the source tasks, because some countries may have non-overlapping labels with the target task\n",
    "    input_data[\"source_task\"] = list(set(input_data[\"source_dict\"][group_by]))\n",
    "\n",
    "    # resample the target to make the number of samples is fixed\n",
    "    \n",
    "   # if len(input_data[\"idx_target\"]) >= target_size:\n",
    "       # input_data[\"idx_target\"] = random.sample(input_data[\"idx_target\"], k = target_size)\n",
    "    #else:\n",
    "       # input_data[\"idx_target\"] = random.choices(input_data[\"idx_target\"], k = target_size)\n",
    "        \n",
    "    \n",
    "    # split the target data into train / validation / test sets\n",
    "    \n",
    "    y_target = [labels[i] for i in input_data[\"idx_target\"]]\n",
    "    input_data[\"idx_train\"], idx_rest, _, y_rest = train_test_split(input_data[\"idx_target\"],\n",
    "                                                              y_target,\n",
    "                                                             train_size = train_size,\n",
    "                                                              random_state = 0, shuffle = True)\n",
    "    \n",
    "    input_data[\"idx_val\"], input_data[\"idx_test\"], _, _ = train_test_split(idx_rest,\n",
    "                                                              y_rest,\n",
    "                                                              train_size = train_size,\n",
    "                                                              test_size = test_size,\n",
    "                                                              random_state = 0, shuffle = True)\n",
    "    \n",
    "\n",
    "    return input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d695275",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = prepare_input_data(geo_df, target_task, group_by = \"cluster\", \n",
    "                                labels = labels,\n",
    "                               target_size = target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c51c7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db5ad7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data ---\n",
    "\n",
    "target_val_loader =  torch.utils.data.DataLoader(torch.utils.data.Subset(data, input_data[\"idx_val\"]), \n",
    "                                              batch_size = 16, shuffle = True, num_workers = 0)\n",
    "target_train_loader =  torch.utils.data.DataLoader(torch.utils.data.Subset(data, input_data[\"idx_train\"]), \n",
    "                                                  batch_size = 16, shuffle = True, num_workers = 0)\n",
    "target_test_loader =  torch.utils.data.DataLoader(torch.utils.data.Subset(data, input_data[\"idx_test\"]), \n",
    "                                                  batch_size = 16, shuffle = True, num_workers = 0)\n",
    "\n",
    "\n",
    "\n",
    "# initialize hyperparameters ---\n",
    "\n",
    "bandit_selects = [None]\n",
    "alpha = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "beta = dict.fromkeys(input_data[\"source_task\"], [1])\n",
    "pi = dict.fromkeys(input_data[\"source_task\"], [0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04a539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miaoxinran/Desktop/source_selection/experiment_eurosat/dataset.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "net, bandit_selects, accs, alpha, beta, pi = bandit_selection(data, input_data, \n",
    "                                                            n_epochs = 2, n_it = 3,\n",
    "                                                            algorithm = algorithm, iter_samples = 160,\n",
    "                                                           output_path = output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance = validation(net, target_test_loader)\n",
    "pd.DataFrame({\"test_acc\": test_performance,\n",
    "             \"algorithm\": algorithm,\n",
    "             \"target_size\": target_size,\n",
    "             \"target_task\": target_task},\n",
    "            index = [0]).to_csv(output_path / Path(str(target_task) + \"_\" + algorithm + \"_\" + str(target_size) + \"_test_acc.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef75272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
